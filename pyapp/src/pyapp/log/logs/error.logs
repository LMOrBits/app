December 1, 2024 > 22:24:29 |  app.api.utils : 19 |   ❌ ERROR  |  No session_id cookie found  
December 1, 2024 > 22:24:29 |  app.api.utils : 32 |   ❌ ERROR  |  Error getting user_id: 404: Please set the cookie  
December 1, 2024 > 22:24:36 |  app.api.utils : 19 |   ❌ ERROR  |  No session_id cookie found  
December 1, 2024 > 22:24:36 |  app.api.utils : 32 |   ❌ ERROR  |  Error getting user_id: 404: Please set the cookie  
December 1, 2024 > 23:06:02 |  app.api.utils : 19 |   ❌ ERROR  |  No session_id cookie found  
December 1, 2024 > 23:06:02 |  app.api.utils : 32 |   ❌ ERROR  |  Error getting user_id: 404: Please set the cookie  
December 1, 2024 > 23:06:32 |  app.api.utils : 19 |   ❌ ERROR  |  No session_id cookie found  
December 1, 2024 > 23:06:32 |  app.api.utils : 32 |   ❌ ERROR  |  Error getting user_id: 404: Please set the cookie  
December 1, 2024 > 23:07:28 |  app.api.utils : 19 |   ❌ ERROR  |  No session_id cookie found  
December 1, 2024 > 23:07:28 |  app.api.utils : 32 |   ❌ ERROR  |  Error getting user_id: 404: Please set the cookie  
December 1, 2024 > 23:09:06 |  app.api.utils : 19 |   ❌ ERROR  |  No session_id cookie found  
December 1, 2024 > 23:09:06 |  app.api.utils : 32 |   ❌ ERROR  |  Error getting user_id: 404: Please set the cookie  
December 1, 2024 > 23:09:20 |  app.shared.db.init : 26 |   ❌ ERROR  |  (psycopg.errors.InvalidTextRepresentation) invalid input syntax for type uuid: "undefined"
CONTEXT:  unnamed portal parameter $1 = '...'
[SQL: SELECT message."Id", message.user_id, message.chat_id, message.message_text, message.message_type, message.created_at 
FROM message LEFT OUTER JOIN feedback ON feedback.message_id = message."Id" 
WHERE message.chat_id = %(chat_id_1)s::UUID AND (feedback.rating != %(rating_1)s::INTEGER OR feedback.message_id IS NULL) ORDER BY message.created_at ASC]
[parameters: {'chat_id_1': 'undefined', 'rating_1': 0}]
(Background on this error at: https://sqlalche.me/e/20/9h9h)  
December 1, 2024 > 23:09:50 |  app.shared.db.init : 26 |   ❌ ERROR  |  (psycopg.errors.InvalidTextRepresentation) invalid input syntax for type uuid: "undefined"
CONTEXT:  unnamed portal parameter $1 = '...'
[SQL: SELECT message."Id", message.user_id, message.chat_id, message.message_text, message.message_type, message.created_at 
FROM message LEFT OUTER JOIN feedback ON feedback.message_id = message."Id" 
WHERE message.chat_id = %(chat_id_1)s::UUID AND (feedback.rating != %(rating_1)s::INTEGER OR feedback.message_id IS NULL) ORDER BY message.created_at ASC]
[parameters: {'chat_id_1': 'undefined', 'rating_1': 0}]
(Background on this error at: https://sqlalche.me/e/20/9h9h)  
December 1, 2024 > 23:16:05 |  app.shared.db.init : 26 |   ❌ ERROR  |  (psycopg.errors.InvalidTextRepresentation) invalid input syntax for type uuid: "undefined"
CONTEXT:  unnamed portal parameter $1 = '...'
[SQL: SELECT message."Id", message.user_id, message.chat_id, message.message_text, message.message_type, message.created_at 
FROM message LEFT OUTER JOIN feedback ON feedback.message_id = message."Id" 
WHERE message.chat_id = %(chat_id_1)s::UUID AND (feedback.rating != %(rating_1)s::INTEGER OR feedback.message_id IS NULL) ORDER BY message.created_at ASC]
[parameters: {'chat_id_1': 'undefined', 'rating_1': 0}]
(Background on this error at: https://sqlalche.me/e/20/9h9h)  
December 2, 2024 > 01:56:32 |  app.api.utils : 29 |   ❌ ERROR  |  User not found. Please reset the cookie.  
December 2, 2024 > 01:56:32 |  app.api.utils : 32 |   ❌ ERROR  |  Error getting user_id: 404: User not found. Please reset the cookie.  
December 2, 2024 > 02:15:08 |  app.api.utils : 29 |   ❌ ERROR  |  User not found. Please reset the cookie.  
December 2, 2024 > 02:15:08 |  app.api.utils : 32 |   ❌ ERROR  |  Error getting user_id: 404: User not found. Please reset the cookie.  
December 2, 2024 > 02:26:09 |  app.api.utils : 19 |   ❌ ERROR  |  No session_id cookie found  
December 2, 2024 > 02:26:09 |  app.api.utils : 32 |   ❌ ERROR  |  Error getting user_id: 404: Please set the cookie  
December 2, 2024 > 02:26:48 |  app.api.utils : 19 |   ❌ ERROR  |  No session_id cookie found  
December 2, 2024 > 02:26:48 |  app.api.utils : 32 |   ❌ ERROR  |  Error getting user_id: 404: Please set the cookie  
December 2, 2024 > 02:28:20 |  app.api.utils : 19 |   ❌ ERROR  |  No session_id cookie found  
December 2, 2024 > 02:28:20 |  app.api.utils : 32 |   ❌ ERROR  |  Error getting user_id: 404: Please set the cookie  
December 2, 2024 > 02:28:39 |  app.api.utils : 29 |   ❌ ERROR  |  User not found. Please reset the cookie.  
December 2, 2024 > 02:28:39 |  app.api.utils : 32 |   ❌ ERROR  |  Error getting user_id: 404: User not found. Please reset the cookie.  
December 2, 2024 > 02:38:34 |  app.shared.db.init : 26 |   ❌ ERROR  |  (psycopg.errors.InvalidTextRepresentation) invalid input syntax for type uuid: "undefined"
CONTEXT:  unnamed portal parameter $3 = '...'
[SQL: INSERT INTO message ("Id", user_id, chat_id, message_text, message_type, created_at) VALUES (%(Id)s::UUID, %(user_id)s::UUID, %(chat_id)s::UUID, %(message_text)s::VARCHAR, %(message_type)s::VARCHAR, %(created_at)s::TIMESTAMP WITHOUT TIME ZONE)]
[parameters: {'Id': UUID('dd5af3cf-bf72-48d4-b856-efc83d51b072'), 'user_id': UUID('270b125b-8be1-4f09-ac2b-95ef7de033d3'), 'chat_id': 'undefined', 'message_text': 'hi', 'message_type': 'simple', 'created_at': datetime.datetime(2024, 12, 2, 2, 38, 34, 367656)}]
(Background on this error at: https://sqlalche.me/e/20/9h9h)  
December 2, 2024 > 02:47:46 |  app.shared.db.init : 26 |   ❌ ERROR  |  (psycopg.errors.InvalidTextRepresentation) invalid input syntax for type uuid: "undefined"
CONTEXT:  unnamed portal parameter $3 = '...'
[SQL: INSERT INTO message ("Id", user_id, chat_id, message_text, message_type, created_at) VALUES (%(Id)s::UUID, %(user_id)s::UUID, %(chat_id)s::UUID, %(message_text)s::VARCHAR, %(message_type)s::VARCHAR, %(created_at)s::TIMESTAMP WITHOUT TIME ZONE)]
[parameters: {'Id': UUID('3c2f29bf-2a97-4cc6-af41-8a6dab735e98'), 'user_id': UUID('270b125b-8be1-4f09-ac2b-95ef7de033d3'), 'chat_id': 'undefined', 'message_text': 'hey', 'message_type': 'simple', 'created_at': datetime.datetime(2024, 12, 2, 2, 47, 46, 497358)}]
(Background on this error at: https://sqlalche.me/e/20/9h9h)  
December 2, 2024 > 02:48:25 |  app.shared.db.init : 26 |   ❌ ERROR  |  (psycopg.errors.InvalidTextRepresentation) invalid input syntax for type uuid: "undefined"
CONTEXT:  unnamed portal parameter $3 = '...'
[SQL: INSERT INTO message ("Id", user_id, chat_id, message_text, message_type, created_at) VALUES (%(Id)s::UUID, %(user_id)s::UUID, %(chat_id)s::UUID, %(message_text)s::VARCHAR, %(message_type)s::VARCHAR, %(created_at)s::TIMESTAMP WITHOUT TIME ZONE)]
[parameters: {'Id': UUID('0a441b85-ed6b-4344-9376-9c44f64b9929'), 'user_id': UUID('270b125b-8be1-4f09-ac2b-95ef7de033d3'), 'chat_id': 'undefined', 'message_text': 'hey', 'message_type': 'simple', 'created_at': datetime.datetime(2024, 12, 2, 2, 48, 25, 120555)}]
(Background on this error at: https://sqlalche.me/e/20/9h9h)  
December 2, 2024 > 02:53:54 |  app.shared.db.init : 26 |   ❌ ERROR  |  (psycopg.errors.InvalidTextRepresentation) invalid input syntax for type uuid: "undefined"
CONTEXT:  unnamed portal parameter $3 = '...'
[SQL: INSERT INTO message ("Id", user_id, chat_id, message_text, message_type, created_at) VALUES (%(Id)s::UUID, %(user_id)s::UUID, %(chat_id)s::UUID, %(message_text)s::VARCHAR, %(message_type)s::VARCHAR, %(created_at)s::TIMESTAMP WITHOUT TIME ZONE)]
[parameters: {'Id': UUID('2de99a20-682f-495e-a6ab-5ba1c316feb4'), 'user_id': UUID('270b125b-8be1-4f09-ac2b-95ef7de033d3'), 'chat_id': 'undefined', 'message_text': 'hi', 'message_type': 'simple', 'created_at': datetime.datetime(2024, 12, 2, 2, 53, 54, 240568)}]
(Background on this error at: https://sqlalche.me/e/20/9h9h)  
December 2, 2024 > 02:54:19 |  app.shared.db.init : 26 |   ❌ ERROR  |  (psycopg.errors.InvalidTextRepresentation) invalid input syntax for type uuid: "undefined"
CONTEXT:  unnamed portal parameter $3 = '...'
[SQL: INSERT INTO message ("Id", user_id, chat_id, message_text, message_type, created_at) VALUES (%(Id)s::UUID, %(user_id)s::UUID, %(chat_id)s::UUID, %(message_text)s::VARCHAR, %(message_type)s::VARCHAR, %(created_at)s::TIMESTAMP WITHOUT TIME ZONE)]
[parameters: {'Id': UUID('fb810cab-e20a-4488-87fe-f34fc8d75f06'), 'user_id': UUID('270b125b-8be1-4f09-ac2b-95ef7de033d3'), 'chat_id': 'undefined', 'message_text': 'hi', 'message_type': 'simple', 'created_at': datetime.datetime(2024, 12, 2, 2, 54, 19, 23225)}]
(Background on this error at: https://sqlalche.me/e/20/9h9h)  
December 2, 2024 > 09:46:16 |  app.api.utils : 29 |   ❌ ERROR  |  User not found. Please reset the cookie.  
December 2, 2024 > 09:46:16 |  app.api.utils : 32 |   ❌ ERROR  |  Error getting user_id: 404: User not found. Please reset the cookie.  
December 2, 2024 > 09:46:40 |  app.api.utils : 29 |   ❌ ERROR  |  User not found. Please reset the cookie.  
December 2, 2024 > 09:46:40 |  app.api.utils : 32 |   ❌ ERROR  |  Error getting user_id: 404: User not found. Please reset the cookie.  
December 2, 2024 > 09:47:05 |  app.shared.db.init : 26 |   ❌ ERROR  |  (psycopg.errors.InvalidTextRepresentation) invalid input syntax for type uuid: "undefined"
CONTEXT:  unnamed portal parameter $3 = '...'
[SQL: INSERT INTO message ("Id", user_id, chat_id, message_text, message_type, created_at) VALUES (%(Id)s::UUID, %(user_id)s::UUID, %(chat_id)s::UUID, %(message_text)s::VARCHAR, %(message_type)s::VARCHAR, %(created_at)s::TIMESTAMP WITHOUT TIME ZONE)]
[parameters: {'Id': UUID('b9ebcbd7-445f-435d-a256-a3406e0edb21'), 'user_id': UUID('cd3dc464-b8a5-4774-bf4a-8a0333ae76c5'), 'chat_id': 'undefined', 'message_text': 'hi', 'message_type': 'simple', 'created_at': datetime.datetime(2024, 12, 2, 9, 47, 5, 329471)}]
(Background on this error at: https://sqlalche.me/e/20/9h9h)  
December 2, 2024 > 09:48:43 |  app.shared.db.init : 26 |   ❌ ERROR  |  (psycopg.errors.InvalidTextRepresentation) invalid input syntax for type uuid: "undefined"
CONTEXT:  unnamed portal parameter $3 = '...'
[SQL: INSERT INTO message ("Id", user_id, chat_id, message_text, message_type, created_at) VALUES (%(Id)s::UUID, %(user_id)s::UUID, %(chat_id)s::UUID, %(message_text)s::VARCHAR, %(message_type)s::VARCHAR, %(created_at)s::TIMESTAMP WITHOUT TIME ZONE)]
[parameters: {'Id': UUID('a9b899e7-12b6-4500-a51b-705f13265c78'), 'user_id': UUID('cd3dc464-b8a5-4774-bf4a-8a0333ae76c5'), 'chat_id': 'undefined', 'message_text': 'hey', 'message_type': 'simple', 'created_at': datetime.datetime(2024, 12, 2, 9, 48, 43, 630462)}]
(Background on this error at: https://sqlalche.me/e/20/9h9h)  
December 2, 2024 > 10:24:16 |  app.shared.db.init : 26 |   ❌ ERROR  |  (psycopg.errors.InvalidTextRepresentation) invalid input syntax for type uuid: "undefined"
CONTEXT:  unnamed portal parameter $3 = '...'
[SQL: INSERT INTO message ("Id", user_id, chat_id, message_text, message_type, created_at) VALUES (%(Id)s::UUID, %(user_id)s::UUID, %(chat_id)s::UUID, %(message_text)s::VARCHAR, %(message_type)s::VARCHAR, %(created_at)s::TIMESTAMP WITHOUT TIME ZONE)]
[parameters: {'Id': UUID('a70580e7-2da6-4fea-a03f-705c1386c2cc'), 'user_id': UUID('cd3dc464-b8a5-4774-bf4a-8a0333ae76c5'), 'chat_id': 'undefined', 'message_text': 'hi', 'message_type': 'simple', 'created_at': datetime.datetime(2024, 12, 2, 10, 24, 16, 166599)}]
(Background on this error at: https://sqlalche.me/e/20/9h9h)  
December 2, 2024 > 10:30:10 |  app.shared.db.init : 26 |   ❌ ERROR  |  (psycopg.errors.InvalidTextRepresentation) invalid input syntax for type uuid: "undefined"
CONTEXT:  unnamed portal parameter $3 = '...'
[SQL: INSERT INTO message ("Id", user_id, chat_id, message_text, message_type, created_at) VALUES (%(Id)s::UUID, %(user_id)s::UUID, %(chat_id)s::UUID, %(message_text)s::VARCHAR, %(message_type)s::VARCHAR, %(created_at)s::TIMESTAMP WITHOUT TIME ZONE)]
[parameters: {'Id': UUID('6f2df72d-fd3c-449e-bf18-a755ef1f7d94'), 'user_id': UUID('cd3dc464-b8a5-4774-bf4a-8a0333ae76c5'), 'chat_id': 'undefined', 'message_text': 'hey', 'message_type': 'simple', 'created_at': datetime.datetime(2024, 12, 2, 10, 30, 10, 630235)}]
(Background on this error at: https://sqlalche.me/e/20/9h9h)  
December 2, 2024 > 10:30:10 |  app.shared.db.init : 26 |   ❌ ERROR  |  (psycopg.errors.InvalidTextRepresentation) invalid input syntax for type uuid: "undefined"
CONTEXT:  unnamed portal parameter $3 = '...'
[SQL: INSERT INTO message ("Id", user_id, chat_id, message_text, message_type, created_at) VALUES (%(Id)s::UUID, %(user_id)s::UUID, %(chat_id)s::UUID, %(message_text)s::VARCHAR, %(message_type)s::VARCHAR, %(created_at)s::TIMESTAMP WITHOUT TIME ZONE)]
[parameters: {'Id': UUID('ef668490-0cf5-4155-9fd9-77dfe3c8cbd8'), 'user_id': UUID('cd3dc464-b8a5-4774-bf4a-8a0333ae76c5'), 'chat_id': 'undefined', 'message_text': 'hey', 'message_type': 'simple', 'created_at': datetime.datetime(2024, 12, 2, 10, 30, 10, 641474)}]
(Background on this error at: https://sqlalche.me/e/20/9h9h)  
December 2, 2024 > 10:30:47 |  app.shared.db.init : 26 |   ❌ ERROR  |  (psycopg.errors.InvalidTextRepresentation) invalid input syntax for type uuid: "undefined"
CONTEXT:  unnamed portal parameter $3 = '...'
[SQL: INSERT INTO message ("Id", user_id, chat_id, message_text, message_type, created_at) VALUES (%(Id)s::UUID, %(user_id)s::UUID, %(chat_id)s::UUID, %(message_text)s::VARCHAR, %(message_type)s::VARCHAR, %(created_at)s::TIMESTAMP WITHOUT TIME ZONE)]
[parameters: {'Id': UUID('c79a7611-5690-41b6-bf72-c4eb4e9a373d'), 'user_id': UUID('cd3dc464-b8a5-4774-bf4a-8a0333ae76c5'), 'chat_id': 'undefined', 'message_text': 'hi', 'message_type': 'simple', 'created_at': datetime.datetime(2024, 12, 2, 10, 30, 47, 6693)}]
(Background on this error at: https://sqlalche.me/e/20/9h9h)  
December 2, 2024 > 10:32:46 |  app.shared.db.init : 26 |   ❌ ERROR  |  (psycopg.errors.InvalidTextRepresentation) invalid input syntax for type uuid: "undefined"
CONTEXT:  unnamed portal parameter $3 = '...'
[SQL: INSERT INTO message ("Id", user_id, chat_id, message_text, message_type, created_at) VALUES (%(Id)s::UUID, %(user_id)s::UUID, %(chat_id)s::UUID, %(message_text)s::VARCHAR, %(message_type)s::VARCHAR, %(created_at)s::TIMESTAMP WITHOUT TIME ZONE)]
[parameters: {'Id': UUID('d68b3fd5-9eb7-40c6-8784-a8abaa0f7167'), 'user_id': UUID('cd3dc464-b8a5-4774-bf4a-8a0333ae76c5'), 'chat_id': 'undefined', 'message_text': 'hi', 'message_type': 'simple', 'created_at': datetime.datetime(2024, 12, 2, 10, 32, 46, 509820)}]
(Background on this error at: https://sqlalche.me/e/20/9h9h)  
December 2, 2024 > 10:35:48 |  app.shared.db.init : 26 |   ❌ ERROR  |  (psycopg.errors.InvalidTextRepresentation) invalid input syntax for type uuid: "undefined"
CONTEXT:  unnamed portal parameter $3 = '...'
[SQL: INSERT INTO message ("Id", user_id, chat_id, message_text, message_type, created_at) VALUES (%(Id)s::UUID, %(user_id)s::UUID, %(chat_id)s::UUID, %(message_text)s::VARCHAR, %(message_type)s::VARCHAR, %(created_at)s::TIMESTAMP WITHOUT TIME ZONE)]
[parameters: {'Id': UUID('420dae0c-6344-460b-b756-b2a859efb38f'), 'user_id': UUID('cd3dc464-b8a5-4774-bf4a-8a0333ae76c5'), 'chat_id': 'undefined', 'message_text': 'hey', 'message_type': 'simple', 'created_at': datetime.datetime(2024, 12, 2, 10, 35, 48, 804340)}]
(Background on this error at: https://sqlalche.me/e/20/9h9h)  
December 2, 2024 > 10:40:26 |  app.shared.db.init : 26 |   ❌ ERROR  |  (psycopg.errors.InvalidTextRepresentation) invalid input syntax for type uuid: "undefined"
CONTEXT:  unnamed portal parameter $3 = '...'
[SQL: INSERT INTO message ("Id", user_id, chat_id, message_text, message_type, created_at) VALUES (%(Id)s::UUID, %(user_id)s::UUID, %(chat_id)s::UUID, %(message_text)s::VARCHAR, %(message_type)s::VARCHAR, %(created_at)s::TIMESTAMP WITHOUT TIME ZONE)]
[parameters: {'Id': UUID('fa21d234-b8d8-4df2-b9fb-f1cdff7638a9'), 'user_id': UUID('cd3dc464-b8a5-4774-bf4a-8a0333ae76c5'), 'chat_id': 'undefined', 'message_text': 'hi ', 'message_type': 'simple', 'created_at': datetime.datetime(2024, 12, 2, 10, 40, 26, 270056)}]
(Background on this error at: https://sqlalche.me/e/20/9h9h)  
December 2, 2024 > 10:52:54 |  app.shared.db.init : 26 |   ❌ ERROR  |  (psycopg.errors.InvalidTextRepresentation) invalid input syntax for type uuid: "undefined"
CONTEXT:  unnamed portal parameter $3 = '...'
[SQL: INSERT INTO message ("Id", user_id, chat_id, message_text, message_type, created_at) VALUES (%(Id)s::UUID, %(user_id)s::UUID, %(chat_id)s::UUID, %(message_text)s::VARCHAR, %(message_type)s::VARCHAR, %(created_at)s::TIMESTAMP WITHOUT TIME ZONE)]
[parameters: {'Id': UUID('3e1a48c1-946a-42f9-8e4e-2a33c1b46acf'), 'user_id': UUID('cd3dc464-b8a5-4774-bf4a-8a0333ae76c5'), 'chat_id': 'undefined', 'message_text': 'hi', 'message_type': 'simple', 'created_at': datetime.datetime(2024, 12, 2, 10, 52, 54, 485871)}]
(Background on this error at: https://sqlalche.me/e/20/9h9h)  
December 2, 2024 > 10:53:12 |  app.shared.db.init : 26 |   ❌ ERROR  |  (psycopg.errors.InvalidTextRepresentation) invalid input syntax for type uuid: "undefined"
CONTEXT:  unnamed portal parameter $3 = '...'
[SQL: INSERT INTO message ("Id", user_id, chat_id, message_text, message_type, created_at) VALUES (%(Id)s::UUID, %(user_id)s::UUID, %(chat_id)s::UUID, %(message_text)s::VARCHAR, %(message_type)s::VARCHAR, %(created_at)s::TIMESTAMP WITHOUT TIME ZONE)]
[parameters: {'Id': UUID('b1efa6a1-8c8a-46cc-9d9c-54f4c360698a'), 'user_id': UUID('cd3dc464-b8a5-4774-bf4a-8a0333ae76c5'), 'chat_id': 'undefined', 'message_text': 'hey', 'message_type': 'simple', 'created_at': datetime.datetime(2024, 12, 2, 10, 53, 12, 592653)}]
(Background on this error at: https://sqlalche.me/e/20/9h9h)  
December 2, 2024 > 10:59:39 |  app.shared.db.init : 26 |   ❌ ERROR  |  (psycopg.errors.InvalidTextRepresentation) invalid input syntax for type uuid: "undefined"
CONTEXT:  unnamed portal parameter $3 = '...'
[SQL: INSERT INTO message ("Id", user_id, chat_id, message_text, message_type, created_at) VALUES (%(Id)s::UUID, %(user_id)s::UUID, %(chat_id)s::UUID, %(message_text)s::VARCHAR, %(message_type)s::VARCHAR, %(created_at)s::TIMESTAMP WITHOUT TIME ZONE)]
[parameters: {'Id': UUID('af5b808e-334f-4cb1-a1f5-36d36cd0e8e7'), 'user_id': UUID('cd3dc464-b8a5-4774-bf4a-8a0333ae76c5'), 'chat_id': 'undefined', 'message_text': 'hi', 'message_type': 'simple', 'created_at': datetime.datetime(2024, 12, 2, 10, 59, 39, 524742)}]
(Background on this error at: https://sqlalche.me/e/20/9h9h)  
December 2, 2024 > 11:00:56 |  app.shared.db.init : 26 |   ❌ ERROR  |  (psycopg.errors.InvalidTextRepresentation) invalid input syntax for type uuid: "undefined"
CONTEXT:  unnamed portal parameter $3 = '...'
[SQL: INSERT INTO message ("Id", user_id, chat_id, message_text, message_type, created_at) VALUES (%(Id)s::UUID, %(user_id)s::UUID, %(chat_id)s::UUID, %(message_text)s::VARCHAR, %(message_type)s::VARCHAR, %(created_at)s::TIMESTAMP WITHOUT TIME ZONE)]
[parameters: {'Id': UUID('e4961c90-2131-484d-84ea-fc8c9b78d93b'), 'user_id': UUID('cd3dc464-b8a5-4774-bf4a-8a0333ae76c5'), 'chat_id': 'undefined', 'message_text': 'hi', 'message_type': 'simple', 'created_at': datetime.datetime(2024, 12, 2, 11, 0, 56, 673357)}]
(Background on this error at: https://sqlalche.me/e/20/9h9h)  
December 2, 2024 > 11:18:28 |  app.shared.db.init : 26 |   ❌ ERROR  |  (psycopg.errors.InvalidTextRepresentation) invalid input syntax for type uuid: "undefined"
CONTEXT:  unnamed portal parameter $3 = '...'
[SQL: INSERT INTO message ("Id", user_id, chat_id, message_text, message_type, created_at) VALUES (%(Id)s::UUID, %(user_id)s::UUID, %(chat_id)s::UUID, %(message_text)s::VARCHAR, %(message_type)s::VARCHAR, %(created_at)s::TIMESTAMP WITHOUT TIME ZONE)]
[parameters: {'Id': UUID('8a085d61-3638-4311-b5cf-5600781b1f91'), 'user_id': UUID('cd3dc464-b8a5-4774-bf4a-8a0333ae76c5'), 'chat_id': 'undefined', 'message_text': 'hi', 'message_type': 'simple', 'created_at': datetime.datetime(2024, 12, 2, 11, 18, 28, 787262)}]
(Background on this error at: https://sqlalche.me/e/20/9h9h)  
December 2, 2024 > 11:20:46 |  app.shared.db.init : 26 |   ❌ ERROR  |  (psycopg.errors.InvalidTextRepresentation) invalid input syntax for type uuid: "undefined"
CONTEXT:  unnamed portal parameter $3 = '...'
[SQL: INSERT INTO message ("Id", user_id, chat_id, message_text, message_type, created_at) VALUES (%(Id)s::UUID, %(user_id)s::UUID, %(chat_id)s::UUID, %(message_text)s::VARCHAR, %(message_type)s::VARCHAR, %(created_at)s::TIMESTAMP WITHOUT TIME ZONE)]
[parameters: {'Id': UUID('b34cc049-4115-4797-bd6c-b74c8ffd2743'), 'user_id': UUID('cd3dc464-b8a5-4774-bf4a-8a0333ae76c5'), 'chat_id': 'undefined', 'message_text': 'hi', 'message_type': 'simple', 'created_at': datetime.datetime(2024, 12, 2, 11, 20, 46, 116626)}]
(Background on this error at: https://sqlalche.me/e/20/9h9h)  
December 2, 2024 > 13:00:23 |  app.api.utils : 29 |   ❌ ERROR  |  User not found. Please reset the cookie.  
December 2, 2024 > 13:00:23 |  app.api.utils : 32 |   ❌ ERROR  |  Error getting user_id: 404: User not found. Please reset the cookie.  
December 2, 2024 > 13:00:42 |  app.shared.db.init : 29 |   ❌ ERROR  |  (builtins.AttributeError) 'str' object has no attribute 'hex'
[SQL: SELECT message."Id", message.user_id, message.chat_id, message.message_text, message.message_type, message.created_at 
FROM message LEFT OUTER JOIN feedback ON feedback.message_id = message."Id" 
WHERE message.chat_id = ? AND (feedback.rating != ? OR feedback.message_id IS NULL) ORDER BY message.created_at ASC]
[parameters: [{}]]  
December 2, 2024 > 13:00:49 |  app.shared.db.init : 29 |   ❌ ERROR  |  (builtins.AttributeError) 'str' object has no attribute 'hex'
[SQL: INSERT INTO message ("Id", user_id, chat_id, message_text, message_type, created_at) VALUES (?, ?, ?, ?, ?, ?)]
[parameters: [{'Id': UUID('b350d58f-f78f-404d-a708-9931a96c013d'), 'user_id': UUID('d8079b03-f31b-411b-b8f8-8eef796e2da1'), 'message_type': 'simple', 'message_text': 'hi', 'created_at': datetime.datetime(2024, 12, 2, 13, 0, 49, 798971), 'chat_id': '08e6306a-4143-4ade-b9f5-94ec3d3e58fd'}]]  
December 2, 2024 > 13:01:09 |  app.shared.db.init : 29 |   ❌ ERROR  |  (builtins.AttributeError) 'str' object has no attribute 'hex'
[SQL: SELECT message."Id", message.user_id, message.chat_id, message.message_text, message.message_type, message.created_at 
FROM message LEFT OUTER JOIN feedback ON feedback.message_id = message."Id" 
WHERE message.chat_id = ? AND (feedback.rating != ? OR feedback.message_id IS NULL) ORDER BY message.created_at ASC]
[parameters: [{}]]  
December 2, 2024 > 13:01:13 |  app.shared.db.init : 29 |   ❌ ERROR  |  (builtins.AttributeError) 'str' object has no attribute 'hex'
[SQL: INSERT INTO message ("Id", user_id, chat_id, message_text, message_type, created_at) VALUES (?, ?, ?, ?, ?, ?)]
[parameters: [{'Id': UUID('89189d04-0eed-468d-a6a9-56acfb01d9e7'), 'user_id': UUID('8b4dc61f-27b6-4f66-921a-355d6bd06dcd'), 'message_type': 'simple', 'message_text': 'hi', 'created_at': datetime.datetime(2024, 12, 2, 13, 1, 13, 623262), 'chat_id': '08e6306a-4143-4ade-b9f5-94ec3d3e58fd'}]]  
December 2, 2024 > 13:11:59 |  app.api.routes : 20 |   ❌ ERROR  |  Failed to load module message: (sqlite3.OperationalError) unable to open database file
(Background on this error at: https://sqlalche.me/e/20/e3q8)  
December 2, 2024 > 13:11:59 |  app.api.routes : 20 |   ❌ ERROR  |  Failed to load module cookie: (sqlite3.OperationalError) unable to open database file
(Background on this error at: https://sqlalche.me/e/20/e3q8)  
December 2, 2024 > 13:11:59 |  app.api.routes : 20 |   ❌ ERROR  |  Failed to load module chat: (sqlite3.OperationalError) unable to open database file
(Background on this error at: https://sqlalche.me/e/20/e3q8)  
December 2, 2024 > 13:11:59 |  app.api.routes : 20 |   ❌ ERROR  |  Failed to load module messages: (sqlite3.OperationalError) unable to open database file
(Background on this error at: https://sqlalche.me/e/20/e3q8)  
December 2, 2024 > 13:12:00 |  app.api.routes : 20 |   ❌ ERROR  |  Failed to load module message: (sqlite3.OperationalError) unable to open database file
(Background on this error at: https://sqlalche.me/e/20/e3q8)  
December 2, 2024 > 13:12:00 |  app.api.routes : 20 |   ❌ ERROR  |  Failed to load module cookie: (sqlite3.OperationalError) unable to open database file
(Background on this error at: https://sqlalche.me/e/20/e3q8)  
December 2, 2024 > 13:12:00 |  app.api.routes : 20 |   ❌ ERROR  |  Failed to load module chat: (sqlite3.OperationalError) unable to open database file
(Background on this error at: https://sqlalche.me/e/20/e3q8)  
December 2, 2024 > 13:12:00 |  app.api.routes : 20 |   ❌ ERROR  |  Failed to load module messages: (sqlite3.OperationalError) unable to open database file
(Background on this error at: https://sqlalche.me/e/20/e3q8)  
December 2, 2024 > 13:14:11 |  app.api.routes : 20 |   ❌ ERROR  |  Failed to load module message: name 'db_folder' is not defined  
December 2, 2024 > 13:14:11 |  app.api.routes : 20 |   ❌ ERROR  |  Failed to load module cookie: name 'db_folder' is not defined  
December 2, 2024 > 13:14:11 |  app.api.routes : 20 |   ❌ ERROR  |  Failed to load module chat: name 'db_folder' is not defined  
December 2, 2024 > 13:14:11 |  app.api.routes : 20 |   ❌ ERROR  |  Failed to load module messages: name 'db_folder' is not defined  
December 2, 2024 > 13:14:58 |  app.api.utils : 29 |   ❌ ERROR  |  User not found. Please reset the cookie.  
December 2, 2024 > 13:14:58 |  app.api.utils : 32 |   ❌ ERROR  |  Error getting user_id: 404: User not found. Please reset the cookie.  
December 2, 2024 > 13:15:23 |  app.shared.db.init : 32 |   ❌ ERROR  |  (builtins.AttributeError) 'str' object has no attribute 'hex'
[SQL: SELECT message."Id", message.user_id, message.chat_id, message.message_text, message.message_type, message.created_at 
FROM message LEFT OUTER JOIN feedback ON feedback.message_id = message."Id" 
WHERE message.chat_id = ? AND (feedback.rating != ? OR feedback.message_id IS NULL) ORDER BY message.created_at ASC]
[parameters: [{}]]  
December 2, 2024 > 13:21:07 |  app.shared.db.init : 32 |   ❌ ERROR  |  (builtins.AttributeError) 'str' object has no attribute 'hex'
[SQL: SELECT message."Id", message.user_id, message.chat_id, message.message_text, message.message_type, message.created_at 
FROM message LEFT OUTER JOIN feedback ON feedback.message_id = message."Id" 
WHERE message.chat_id = ? AND (feedback.rating != ? OR feedback.message_id IS NULL) ORDER BY message.created_at ASC]
[parameters: [{}]]  
December 2, 2024 > 13:24:53 |  app.shared.db.init : 32 |   ❌ ERROR  |  (builtins.AttributeError) 'str' object has no attribute 'hex'
[SQL: SELECT message."Id", message.user_id, message.chat_id, message.message_text, message.message_type, message.created_at 
FROM message LEFT OUTER JOIN feedback ON feedback.message_id = message."Id" 
WHERE message.chat_id = ? AND (feedback.rating != ? OR feedback.message_id IS NULL) ORDER BY message.created_at ASC]
[parameters: [{}]]  
December 2, 2024 > 13:28:14 |  app.shared.db.init : 32 |   ❌ ERROR  |  (builtins.AttributeError) 'str' object has no attribute 'hex'
[SQL: SELECT chat."Id", chat.created_at, chat.user_id, chat.title 
FROM chat 
WHERE chat.user_id = ? ORDER BY chat.created_at DESC]
[parameters: [{}]]  
December 2, 2024 > 13:28:14 |  app.shared.db.init : 32 |   ❌ ERROR  |  (builtins.AttributeError) 'str' object has no attribute 'hex'
[SQL: SELECT message."Id", message.user_id, message.chat_id, message.message_text, message.message_type, message.created_at 
FROM message LEFT OUTER JOIN feedback ON feedback.message_id = message."Id" 
WHERE message.chat_id = ? AND (feedback.rating != ? OR feedback.message_id IS NULL) ORDER BY message.created_at ASC]
[parameters: [{}]]  
December 2, 2024 > 13:37:34 |  app.shared.db.init : 32 |   ❌ ERROR  |  (builtins.AttributeError) 'str' object has no attribute 'hex'
[SQL: SELECT message."Id", message.user_id, message.chat_id, message.message_text, message.message_type, message.created_at 
FROM message LEFT OUTER JOIN feedback ON feedback.message_id = message."Id" 
WHERE message.chat_id = ? AND (feedback.rating != ? OR feedback.message_id IS NULL) ORDER BY message.created_at ASC]
[parameters: [{}]]  
December 2, 2024 > 13:38:19 |  app.shared.db.init : 32 |   ❌ ERROR  |  (builtins.AttributeError) 'str' object has no attribute 'hex'
[SQL: SELECT message."Id", message.user_id, message.chat_id, message.message_text, message.message_type, message.created_at 
FROM message LEFT OUTER JOIN feedback ON feedback.message_id = message."Id" 
WHERE message.chat_id = ? AND (feedback.rating != ? OR feedback.message_id IS NULL) ORDER BY message.created_at ASC]
[parameters: [{}]]  
December 2, 2024 > 13:39:05 |  app.shared.db.init : 32 |   ❌ ERROR  |  (builtins.AttributeError) 'str' object has no attribute 'hex'
[SQL: SELECT message."Id", message.user_id, message.chat_id, message.message_text, message.message_type, message.created_at 
FROM message LEFT OUTER JOIN feedback ON feedback.message_id = message."Id" 
WHERE message.chat_id = ? AND (feedback.rating != ? OR feedback.message_id IS NULL) ORDER BY message.created_at ASC]
[parameters: [{}]]  
December 2, 2024 > 13:42:57 |  app.shared.db.init : 32 |   ❌ ERROR  |  (builtins.AttributeError) 'str' object has no attribute 'hex'
[SQL: SELECT message."Id", message.user_id, message.chat_id, message.message_text, message.message_type, message.created_at 
FROM message LEFT OUTER JOIN feedback ON feedback.message_id = message."Id" 
WHERE message.chat_id = ? AND (feedback.rating != ? OR feedback.message_id IS NULL) ORDER BY message.created_at ASC]
[parameters: [{}]]  
December 2, 2024 > 13:45:19 |  app.shared.db.init : 32 |   ❌ ERROR  |  (builtins.AttributeError) 'str' object has no attribute 'hex'
[SQL: SELECT message."Id", message.user_id, message.chat_id, message.message_text, message.message_type, message.created_at 
FROM message LEFT OUTER JOIN feedback ON feedback.message_id = message."Id" 
WHERE message.chat_id = ? AND (feedback.rating != ? OR feedback.message_id IS NULL) ORDER BY message.created_at ASC]
[parameters: [{}]]  
December 2, 2024 > 13:48:44 |  app.shared.db.init : 32 |   ❌ ERROR  |  (builtins.AttributeError) 'str' object has no attribute 'hex'
[SQL: SELECT message."Id", message.user_id, message.chat_id, message.message_text, message.message_type, message.created_at 
FROM message LEFT OUTER JOIN feedback ON feedback.message_id = message."Id" 
WHERE message.chat_id = ? AND (feedback.rating != ? OR feedback.message_id IS NULL) ORDER BY message.created_at ASC]
[parameters: [{}]]  
December 2, 2024 > 13:51:24 |  app.shared.db.init : 32 |   ❌ ERROR  |  Level 'fuck yse ' does not exist  
December 2, 2024 > 13:51:24 |  app.api.utils : 33 |   ❌ ERROR  |  Error getting user_id: Level 'fuck yse ' does not exist  
December 2, 2024 > 14:01:53 |  app.shared.db.init : 32 |   ❌ ERROR  |  (builtins.AttributeError) 'str' object has no attribute 'hex'
[SQL: SELECT message."Id", message.user_id, message.chat_id, message.message_text, message.message_type, message.created_at 
FROM message LEFT OUTER JOIN feedback ON feedback.message_id = message."Id" 
WHERE message.chat_id = ? AND (feedback.rating != ? OR feedback.message_id IS NULL) ORDER BY message.created_at ASC]
[parameters: [{}]]  
December 2, 2024 > 14:02:19 |  app.shared.db.init : 32 |   ❌ ERROR  |  (builtins.AttributeError) 'str' object has no attribute 'hex'
[SQL: SELECT message."Id", message.user_id, message.chat_id, message.message_text, message.message_type, message.created_at 
FROM message LEFT OUTER JOIN feedback ON feedback.message_id = message."Id" 
WHERE message.chat_id = ? AND (feedback.rating != ? OR feedback.message_id IS NULL) ORDER BY message.created_at ASC]
[parameters: [{}]]  
December 2, 2024 > 14:02:53 |  app.shared.db.init : 32 |   ❌ ERROR  |  (builtins.AttributeError) 'str' object has no attribute 'hex'
[SQL: SELECT message."Id", message.user_id, message.chat_id, message.message_text, message.message_type, message.created_at 
FROM message LEFT OUTER JOIN feedback ON feedback.message_id = message."Id" 
WHERE message.chat_id = ? AND (feedback.rating != ? OR feedback.message_id IS NULL) ORDER BY message.created_at ASC]
[parameters: [{}]]  
December 2, 2024 > 14:05:01 |  app.shared.db.init : 32 |   ❌ ERROR  |  (builtins.AttributeError) 'str' object has no attribute 'hex'
[SQL: SELECT message."Id", message.user_id, message.chat_id, message.message_text, message.message_type, message.created_at 
FROM message 
WHERE message.chat_id = ? ORDER BY message.created_at ASC]
[parameters: [{}]]  
December 2, 2024 > 14:09:23 |  app.shared.db.init : 32 |   ❌ ERROR  |  (builtins.AttributeError) 'str' object has no attribute 'hex'
[SQL: INSERT INTO message ("Id", user_id, chat_id, message_text, message_type, created_at) VALUES (?, ?, ?, ?, ?, ?)]
[parameters: [{'message_text': 'hi', 'user_id': UUID('deb5c361-8f83-4f01-b2d9-73e2441f85c8'), 'message_type': 'simple', 'chat_id': '248d526b-9038-4229-908c-df49f5e65bbe', 'created_at': datetime.datetime(2024, 12, 2, 14, 9, 23, 482280), 'Id': UUID('f543452f-f3d6-4446-9f0c-13c3e7fb5576')}]]  
December 2, 2024 > 14:10:49 |  app.shared.db.init : 32 |   ❌ ERROR  |  (builtins.AttributeError) 'str' object has no attribute 'hex'
[SQL: INSERT INTO message ("Id", user_id, chat_id, message_text, message_type, created_at) VALUES (?, ?, ?, ?, ?, ?)]
[parameters: [{'user_id': UUID('00000000-0000-0000-0000-000000000000'), 'Id': UUID('bdcb1dd4-10fe-49eb-8b1a-ebc168452070'), 'message_text': 'Hello! How can I assist ... (6 characters truncated) ... oday?', 'message_type': 'simple', 'created_at': datetime.datetime(2024, 12, 2, 14, 10, 49, 488447), 'chat_id': '248d526b-9038-4229-908c-df49f5e65bbe'}]]  
December 2, 2024 > 14:10:55 |  app.shared.db.init : 32 |   ❌ ERROR  |  (builtins.AttributeError) 'str' object has no attribute 'hex'
[SQL: INSERT INTO message ("Id", user_id, chat_id, message_text, message_type, created_at) VALUES (?, ?, ?, ?, ?, ?)]
[parameters: [{'user_id': UUID('00000000-0000-0000-0000-000000000000'), 'Id': UUID('8bf16968-8d1f-44de-aab9-ecdad4127551'), 'message_text': "I'm just a computer pro ... (88 characters truncated) ...  today?", 'message_type': 'simple', 'created_at': datetime.datetime(2024, 12, 2, 14, 10, 55, 8949), 'chat_id': '248d526b-9038-4229-908c-df49f5e65bbe'}]]  
December 3, 2024 > 10:46:12 |  app.api.routes : 20 |   ❌ ERROR  |  Failed to load module message: cannot import name 'stream_text' from 'app.features.stream.main' (/Users/parsa/Desk/projects/university/slmops-project/application/slmops-application-qa/backend/app/features/stream/main.py)  
December 3, 2024 > 10:52:42 |  app.api.routes : 20 |   ❌ ERROR  |  Failed to load module message: invalid syntax. Perhaps you forgot a comma? (main.py, line 43)  
December 3, 2024 > 10:52:42 |  app.api.routes : 20 |   ❌ ERROR  |  Failed to load module messages: invalid syntax. Perhaps you forgot a comma? (main.py, line 43)  
December 3, 2024 > 17:26:09 |  app.api.routes : 20 |   ❌ ERROR  |  Failed to load module message: No module named 'app.features.stream.utils.tools'  
December 3, 2024 > 17:28:30 |  app.api.routes : 20 |   ❌ ERROR  |  Failed to load module message: No module named 'app.features.stream.utils.tools'  
December 3, 2024 > 17:28:48 |  app.api.routes : 20 |   ❌ ERROR  |  Failed to load module message: No module named 'app.features.stream.utils.tools'  
December 3, 2024 > 17:31:02 |  app.api.routes : 20 |   ❌ ERROR  |  Failed to load module message: No module named 'app.features.stream.utils.tools'  
December 3, 2024 > 17:56:30 |  app.api.routes : 20 |   ❌ ERROR  |  Failed to load module message: No module named 'app.shared.libs'  
December 3, 2024 > 17:56:30 |  app.api.routes : 20 |   ❌ ERROR  |  Failed to load module messages: No module named 'app.shared.libs'  
December 3, 2024 > 17:56:30 |  app.api.routes : 20 |   ❌ ERROR  |  Failed to load module message: No module named 'app.shared.libs'  
December 3, 2024 > 17:56:30 |  app.api.routes : 20 |   ❌ ERROR  |  Failed to load module messages: No module named 'app.shared.libs'  
December 3, 2024 > 17:57:18 |  app.api.routes : 20 |   ❌ ERROR  |  Failed to load module message: No module named 'app.shared.libs.libs'  
December 3, 2024 > 17:57:18 |  app.api.routes : 20 |   ❌ ERROR  |  Failed to load module messages: cannot import name 'UIMessage' from 'app.shared.libs.openai.prompt' (/Users/parsa/Desk/projects/university/slmops-project/application/slmops-application-qa/backend/app/shared/libs/openai/prompt.py)  
December 3, 2024 > 17:57:27 |  app.api.routes : 20 |   ❌ ERROR  |  Failed to load module message: No module named 'app.shared.libs.libs'  
December 3, 2024 > 17:57:27 |  app.api.routes : 20 |   ❌ ERROR  |  Failed to load module messages: cannot import name 'UIMessage' from 'app.shared.libs.openai.prompt' (/Users/parsa/Desk/projects/university/slmops-project/application/slmops-application-qa/backend/app/shared/libs/openai/prompt.py)  
December 3, 2024 > 17:58:03 |  app.api.routes : 20 |   ❌ ERROR  |  Failed to load module message: No module named 'app.shared.libs.libs'  
December 3, 2024 > 18:00:07 |  app.api.routes : 20 |   ❌ ERROR  |  Failed to load module message: No module named 'app.shared.libs.libs'  
December 3, 2024 > 18:00:10 |  app.api.routes : 20 |   ❌ ERROR  |  Failed to load module message: No module named 'app.shared.libs.libs'  
December 3, 2024 > 18:00:11 |  app.api.routes : 20 |   ❌ ERROR  |  Failed to load module message: No module named 'app.shared.libs.libs'  
December 3, 2024 > 18:00:57 |  app.api.routes : 20 |   ❌ ERROR  |  Failed to load module  <module 'message' from '/Users/parsa/Desk/projects/university/slmops-project/application/slmops-application-qa/backend/app/api/routes/message.py'> message: No module named 'app.shared.libs.libs'  
December 3, 2024 > 18:01:00 |  app.api.routes : 20 |   ❌ ERROR  |  Failed to load module <module 'message' from '/Users/parsa/Desk/projects/university/slmops-project/application/slmops-application-qa/backend/app/api/routes/message.py'> message: No module named 'app.shared.libs.libs'  
December 3, 2024 > 18:02:40 |  app.api.routes : 20 |   ❌ ERROR  |  Failed to load module <module 'message' from '/Users/parsa/Desk/projects/university/slmops-project/application/slmops-application-qa/backend/app/api/routes/message.py'> message: No module named 'app.shared.libs.libs'  
December 3, 2024 > 18:02:45 |  app.api.routes : 20 |   ❌ ERROR  |  Failed to load module <module 'message' from '/Users/parsa/Desk/projects/university/slmops-project/application/slmops-application-qa/backend/app/api/routes/message.py'> message: No module named 'app.shared.libs.libs'  
December 3, 2024 > 18:02:46 |  app.api.routes : 20 |   ❌ ERROR  |  Failed to load module <module 'message' from '/Users/parsa/Desk/projects/university/slmops-project/application/slmops-application-qa/backend/app/api/routes/message.py'> message: No module named 'app.shared.libs.libs'  
December 3, 2024 > 18:03:25 |  app.api.routes : 20 |   ❌ ERROR  |  Failed to load module <module 'message' from '/Users/parsa/Desk/projects/university/slmops-project/application/slmops-application-qa/backend/app/api/routes/message.py'> message: No module named 'app.shared.libs.libs'  
December 3, 2024 > 18:03:48 |  app.api.routes : 20 |   ❌ ERROR  |  Failed to load module <module 'message' from '/Users/parsa/Desk/projects/university/slmops-project/application/slmops-application-qa/backend/app/api/routes/message.py'> message: No module named 'app.shared.libs.libs'  
December 3, 2024 > 18:04:17 |  app.api.routes : 20 |   ❌ ERROR  |  Failed to load module <module 'message' from '/Users/parsa/Desk/projects/university/slmops-project/application/slmops-application-qa/backend/app/api/routes/message.py'> message: No module named 'app.shared.libs.libs'  
December 3, 2024 > 18:04:48 |  app.api.routes : 20 |   ❌ ERROR  |  Failed to load module <module 'message' from '/Users/parsa/Desk/projects/university/slmops-project/application/slmops-application-qa/backend/app/api/routes/message.py'> message: No module named 'app.shared.libs.libs'  
December 3, 2024 > 18:04:48 |  app.api.routes : 20 |   ❌ ERROR  |  Failed to load module <module 'message' from '/Users/parsa/Desk/projects/university/slmops-project/application/slmops-application-qa/backend/app/api/routes/message.py'> message: No module named 'app.shared.libs.libs'  
December 3, 2024 > 18:06:10 |  app.api.routes : 20 |   ❌ ERROR  |  Failed to load module <module 'message' from '/Users/parsa/Desk/projects/university/slmops-project/application/slmops-application-qa/backend/app/api/routes/message.py'> message: No module named 'app.shared.libs.libs'  
December 3, 2024 > 18:06:22 |  app.api.routes : 20 |   ❌ ERROR  |  Failed to load module <module 'message' from '/Users/parsa/Desk/projects/university/slmops-project/application/slmops-application-qa/backend/app/api/routes/message.py'> message: No module named 'app.features.libs'  
December 3, 2024 > 18:06:26 |  app.api.routes : 20 |   ❌ ERROR  |  Failed to load module <module 'message' from '/Users/parsa/Desk/projects/university/slmops-project/application/slmops-application-qa/backend/app/api/routes/message.py'> message: No module named 'app.features.libs'  
December 3, 2024 > 18:06:27 |  app.api.routes : 20 |   ❌ ERROR  |  Failed to load module <module 'message' from '/Users/parsa/Desk/projects/university/slmops-project/application/slmops-application-qa/backend/app/api/routes/message.py'> message: No module named 'app.features.libs'  
December 4, 2024 > 17:25:27 |  app.api.routes : 20 |   ❌ ERROR  |  Failed to load module <module 'message' from '/Users/parsa/Desk/projects/university/slmops-project/application/slmops-application-qa/backend/app/api/routes/message.py'> message: [Errno 8] nodename nor servname provided, or not known  
December 4, 2024 > 17:25:29 |  app.api.routes : 20 |   ❌ ERROR  |  Failed to load module <module 'message' from '/Users/parsa/Desk/projects/university/slmops-project/application/slmops-application-qa/backend/app/api/routes/message.py'> message: [Errno 8] nodename nor servname provided, or not known  
December 4, 2024 > 17:27:20 |  app.api.routes : 20 |   ❌ ERROR  |  Failed to load module <module 'message' from '/Users/parsa/Desk/projects/university/slmops-project/application/slmops-application-qa/backend/app/api/routes/message.py'> message: [Errno 8] nodename nor servname provided, or not known  
December 4, 2024 > 17:27:22 |  app.api.routes : 20 |   ❌ ERROR  |  Failed to load module <module 'message' from '/Users/parsa/Desk/projects/university/slmops-project/application/slmops-application-qa/backend/app/api/routes/message.py'> message: [Errno 8] nodename nor servname provided, or not known  
December 4, 2024 > 17:28:05 |  app.api.routes : 20 |   ❌ ERROR  |  Failed to load module <module 'message' from '/Users/parsa/Desk/projects/university/slmops-project/application/slmops-application-qa/backend/app/api/routes/message.py'> message: [Errno 8] nodename nor servname provided, or not known  
December 4, 2024 > 17:28:32 |  app.api.routes : 20 |   ❌ ERROR  |  Failed to load module <module 'message' from '/Users/parsa/Desk/projects/university/slmops-project/application/slmops-application-qa/backend/app/api/routes/message.py'> message: [Errno 8] nodename nor servname provided, or not known  
December 4, 2024 > 17:31:03 |  app.api.routes : 20 |   ❌ ERROR  |  Failed to load module <module 'message' from '/Users/parsa/Desk/projects/university/slmops-project/application/slmops-application-qa/backend/app/api/routes/message.py'> message: Storage folder /Users/parsa/Desk/projects/university/slmops-project/application/slmops-application-qa/backend/data/vectoredb is already accessed by another instance of Qdrant client. If you require concurrent access, use Qdrant server instead.  
December 4, 2024 > 17:31:18 |  app.api.routes : 20 |   ❌ ERROR  |  Failed to load module <module 'message' from '/Users/parsa/Desk/projects/university/slmops-project/application/slmops-application-qa/backend/app/api/routes/message.py'> message: Storage folder /Users/parsa/Desk/projects/university/slmops-project/application/slmops-application-qa/backend/data/vectoredb is already accessed by another instance of Qdrant client. If you require concurrent access, use Qdrant server instead.  
December 4, 2024 > 17:32:20 |  app.api.routes : 20 |   ❌ ERROR  |  Failed to load module <module 'message' from '/Users/parsa/Desk/projects/university/slmops-project/application/slmops-application-qa/backend/app/api/routes/message.py'> message: [Errno 61] Connection refused  
December 4, 2024 > 17:32:22 |  app.api.routes : 20 |   ❌ ERROR  |  Failed to load module <module 'message' from '/Users/parsa/Desk/projects/university/slmops-project/application/slmops-application-qa/backend/app/api/routes/message.py'> message: Collection demo_collection already exists  
December 4, 2024 > 17:33:19 |  app.api.routes : 20 |   ❌ ERROR  |  Failed to load module <module 'message' from '/Users/parsa/Desk/projects/university/slmops-project/application/slmops-application-qa/backend/app/api/routes/message.py'> message: [Errno 61] Connection refused  
December 4, 2024 > 17:33:33 |  app.api.routes : 20 |   ❌ ERROR  |  Failed to load module <module 'message' from '/Users/parsa/Desk/projects/university/slmops-project/application/slmops-application-qa/backend/app/api/routes/message.py'> message: [Errno 61] Connection refused  
December 4, 2024 > 17:37:09 |  app.api.routes : 20 |   ❌ ERROR  |  Failed to load module <module 'message' from '/Users/parsa/Desk/projects/university/slmops-project/application/slmops-application-qa/backend/app/api/routes/message.py'> message: Storage folder /Users/parsa/Desk/projects/university/slmops-project/application/slmops-application-qa/backend/data/vectoredb is already accessed by another instance of Qdrant client. If you require concurrent access, use Qdrant server instead.  
December 4, 2024 > 17:38:27 |  app.api.routes : 20 |   ❌ ERROR  |  Failed to load module <module 'message' from '/Users/parsa/Desk/projects/university/slmops-project/application/slmops-application-qa/backend/app/api/routes/message.py'> message: Storage folder /Users/parsa/Desk/projects/university/slmops-project/application/slmops-application-qa/backend/data/vectoredb is already accessed by another instance of Qdrant client. If you require concurrent access, use Qdrant server instead.  
December 4, 2024 > 17:38:31 |  app.api.routes : 20 |   ❌ ERROR  |  Failed to load module <module 'message' from '/Users/parsa/Desk/projects/university/slmops-project/application/slmops-application-qa/backend/app/api/routes/message.py'> message: Storage folder /Users/parsa/Desk/projects/university/slmops-project/application/slmops-application-qa/backend/data/vectoredb is already accessed by another instance of Qdrant client. If you require concurrent access, use Qdrant server instead.  
December 5, 2024 > 00:17:45 |  app.api.routes : 20 |   ❌ ERROR  |  Failed to load module <module 'message' from '/Users/parsa/Desk/projects/university/slmops-project/application/slmops-application-qa/backend/app/api/routes/message.py'> message: 'dict' object has no attribute 'markdown'  
December 5, 2024 > 00:17:46 |  app.api.routes : 20 |   ❌ ERROR  |  Failed to load module <module 'message' from '/Users/parsa/Desk/projects/university/slmops-project/application/slmops-application-qa/backend/app/api/routes/message.py'> message: 'dict' object has no attribute 'markdown'  
December 5, 2024 > 00:20:18 |  app.api.routes : 20 |   ❌ ERROR  |  Failed to load module <module 'message' from '/Users/parsa/Desk/projects/university/slmops-project/application/slmops-application-qa/backend/app/api/routes/message.py'> message: Expected metadata value to be a str, int, float or bool, got {'question': 'Can I change my seat assignment after I have checked in?', 'answer': 'As long as your boarding pass has not yet been printed, you can still change your seat number after check-in. Click for details.', 'source': 'https://www.turkishairlines.com/en-int/any-questions/check-in-questions/index.html'} which is a dict in upsert.

Try filtering complex metadata from the document using langchain_community.vectorstores.utils.filter_complex_metadata.  
December 5, 2024 > 00:21:06 |  app.api.routes : 20 |   ❌ ERROR  |  Failed to load module <module 'message' from '/Users/parsa/Desk/projects/university/slmops-project/application/slmops-application-qa/backend/app/api/routes/message.py'> message: Expected metadata value to be a str, int, float or bool, got {'question': 'Can I change my seat assignment after I have checked in?', 'answer': 'As long as your boarding pass has not yet been printed, you can still change your seat number after check-in. Click for details.', 'source': 'https://www.turkishairlines.com/en-int/any-questions/check-in-questions/index.html'} which is a dict in upsert.

Try filtering complex metadata from the document using langchain_community.vectorstores.utils.filter_complex_metadata.  
December 5, 2024 > 00:21:08 |  app.api.routes : 20 |   ❌ ERROR  |  Failed to load module <module 'message' from '/Users/parsa/Desk/projects/university/slmops-project/application/slmops-application-qa/backend/app/api/routes/message.py'> message: Expected metadata value to be a str, int, float or bool, got {'question': 'Can I change my seat assignment after I have checked in?', 'answer': 'As long as your boarding pass has not yet been printed, you can still change your seat number after check-in. Click for details.', 'source': 'https://www.turkishairlines.com/en-int/any-questions/check-in-questions/index.html'} which is a dict in upsert.

Try filtering complex metadata from the document using langchain_community.vectorstores.utils.filter_complex_metadata.  
December 5, 2024 > 00:25:22 |  app.api.routes : 20 |   ❌ ERROR  |  Failed to load module <module 'message' from '/Users/parsa/Desk/projects/university/slmops-project/application/slmops-application-qa/backend/app/api/routes/message.py'> message: Expected metadata value to be a str, int, float or bool, got {'question': 'Can I change my seat assignment after I have checked in?', 'answer': 'As long as your boarding pass has not yet been printed, you can still change your seat number after check-in. Click for details.', 'source': 'https://www.turkishairlines.com/en-int/any-questions/check-in-questions/index.html'} which is a dict in upsert.

Try filtering complex metadata from the document using langchain_community.vectorstores.utils.filter_complex_metadata.  
December 5, 2024 > 00:29:28 |  app.api.routes : 20 |   ❌ ERROR  |  Failed to load module <module 'message' from '/Users/parsa/Desk/projects/university/slmops-project/application/slmops-application-qa/backend/app/api/routes/message.py'> message: Expected metadata value to be a str, int, float or bool, got {'question': 'Can I change my seat assignment after I have checked in?', 'answer': 'As long as your boarding pass has not yet been printed, you can still change your seat number after check-in. Click for details.', 'source': 'https://www.turkishairlines.com/en-int/any-questions/check-in-questions/index.html'} which is a dict in upsert.

Try filtering complex metadata from the document using langchain_community.vectorstores.utils.filter_complex_metadata.  
December 5, 2024 > 16:08:15 |  fastembed.common.model_management : 264 |   ❌ ERROR  |  Could not download model from HuggingFace: An error happened while trying to locate the files on the Hub and we cannot find the appropriate snapshot folder for the specified revision on the local disk. Please check your internet connection and try again. Falling back to other sources.  
December 5, 2024 > 16:08:15 |  fastembed.common.model_management : 283 |   ❌ ERROR  |  Could not download model from either source, sleeping for 3.0 seconds, 2 retries left.  
December 5, 2024 > 16:08:18 |  fastembed.common.model_management : 264 |   ❌ ERROR  |  Could not download model from HuggingFace: An error happened while trying to locate the files on the Hub and we cannot find the appropriate snapshot folder for the specified revision on the local disk. Please check your internet connection and try again. Falling back to other sources.  
December 5, 2024 > 16:08:18 |  fastembed.common.model_management : 283 |   ❌ ERROR  |  Could not download model from either source, sleeping for 9.0 seconds, 1 retries left.  
December 5, 2024 > 16:08:27 |  fastembed.common.model_management : 264 |   ❌ ERROR  |  Could not download model from HuggingFace: An error happened while trying to locate the files on the Hub and we cannot find the appropriate snapshot folder for the specified revision on the local disk. Please check your internet connection and try again. Falling back to other sources.  
December 5, 2024 > 16:08:27 |  fastembed.common.model_management : 283 |   ❌ ERROR  |  Could not download model from either source, sleeping for 27.0 seconds, 0 retries left.  
December 5, 2024 > 16:08:54 |  app.api.routes : 20 |   ❌ ERROR  |  Failed to load module <module 'message' from '/Users/parsa/Desk/projects/university/slmops-project/application/slmops-application-qa/backend/app/api/routes/message.py'> message: 1 validation error for FastEmbedEmbeddings
  Value error, Could not load model BAAI/bge-small-en-v1.5 from any source. [type=value_error, input_value={'model_name': 'BAAI/bge-...l': None, 'model': None}, input_type=dict]
    For further information visit https://errors.pydantic.dev/2.9/v/value_error  
December 5, 2024 > 16:08:55 |  fastembed.common.model_management : 264 |   ❌ ERROR  |  Could not download model from HuggingFace: An error happened while trying to locate the files on the Hub and we cannot find the appropriate snapshot folder for the specified revision on the local disk. Please check your internet connection and try again. Falling back to other sources.  
December 5, 2024 > 16:08:55 |  fastembed.common.model_management : 283 |   ❌ ERROR  |  Could not download model from either source, sleeping for 3.0 seconds, 2 retries left.  
December 5, 2024 > 16:08:58 |  fastembed.common.model_management : 264 |   ❌ ERROR  |  Could not download model from HuggingFace: An error happened while trying to locate the files on the Hub and we cannot find the appropriate snapshot folder for the specified revision on the local disk. Please check your internet connection and try again. Falling back to other sources.  
December 5, 2024 > 16:08:58 |  fastembed.common.model_management : 283 |   ❌ ERROR  |  Could not download model from either source, sleeping for 9.0 seconds, 1 retries left.  
December 5, 2024 > 16:09:07 |  fastembed.common.model_management : 264 |   ❌ ERROR  |  Could not download model from HuggingFace: An error happened while trying to locate the files on the Hub and we cannot find the appropriate snapshot folder for the specified revision on the local disk. Please check your internet connection and try again. Falling back to other sources.  
December 5, 2024 > 16:09:07 |  fastembed.common.model_management : 283 |   ❌ ERROR  |  Could not download model from either source, sleeping for 27.0 seconds, 0 retries left.  
December 5, 2024 > 16:09:34 |  app.api.routes : 20 |   ❌ ERROR  |  Failed to load module <module 'message' from '/Users/parsa/Desk/projects/university/slmops-project/application/slmops-application-qa/backend/app/api/routes/message.py'> message: 1 validation error for FastEmbedEmbeddings
  Value error, Could not load model BAAI/bge-small-en-v1.5 from any source. [type=value_error, input_value={'model_name': 'BAAI/bge-...l': None, 'model': None}, input_type=dict]
    For further information visit https://errors.pydantic.dev/2.9/v/value_error  
May 7, 2025 > 09:37:48 |  serve.utils.mlflow.config : 246 |   ❌ ERROR  |  MLflow error checking qa_model version: INVALID_PARAMETER_VALUE: Registered model alias champion not found.  
May 7, 2025 > 09:37:48 |  serve.utils.mlflow.config : 208 |   ❌ ERROR  |  MLflow error while adding model qa_model: INVALID_PARAMETER_VALUE: Registered model alias champion not found.  
May 7, 2025 > 09:38:08 |  serve.utils.mlflow.config : 460 |   ❌ ERROR  |  Error getting path for rag_model: No path found for model rag_model  
May 7, 2025 > 09:38:10 |  serve._cli.task : 33 |   ❌ ERROR  |  [32mtask: [serve] echo "Starting LlamaCpp server and waiting for it to be ready..."
[0m[32mtask: [serve] container_id=$(docker run -d \
  --name lmorbits-llamacpp-rag_model \
  -p 8000:8000 \
  -p 8080:8080 \
  -v /Users/parsa/Desk/projects/university/slmops-project/slmops-thesis/app_projects/app/pyapp/notebooks/models/rag_model/model_path/artifacts:/models \
  ghcr.io/ggerganov/llama.cpp:server \
  -m /models/model.gguf)

while ! docker logs $container_id 2>&1 | grep -q "GET /health 127.0.0.1 200"; do
  echo "Loading model and starting server..."
  docker logs --tail 10 $container_id
  sleep 1
done
echo "LlamaCpp server is ready!"

[0mdocker: Error response from daemon: Conflict. The container name "/lmorbits-llamacpp-rag_model" is already in use by container "a5cd7303de7a12784e1582eb6e85a63a0e9b15b26539b359caf872c64e69e040". You have to remove (or rename) that container to be able to reuse that name.
See 'docker run --help'.
[31mtask: Failed to run task "serve": exit status 125
[0m  
May 7, 2025 > 09:38:42 |  serve.servers.llamacpp.serve : 97 |   ❌ ERROR  |  Failed to add server instance: Model ID 'rag_model' already exists  
May 7, 2025 > 09:38:53 |  serve.servers.llamacpp.serve : 97 |   ❌ ERROR  |  Failed to add server instance: Model ID 'rag_model' already exists  
May 7, 2025 > 09:40:10 |  serve.utils.mlflow.config : 460 |   ❌ ERROR  |  Error getting path for rag_model: No path found for model rag_model  
May 7, 2025 > 09:40:42 |  serve._cli.task : 33 |   ❌ ERROR  |  [32mtask: [serve] echo "Starting LlamaCpp server and waiting for it to be ready..."
[0m[32mtask: [serve] container_id=$(docker run -d \
  --name lmorbits-llamacpp-rag_model \
  -p 8000:8000 \
  -p 8080:8080 \
  -v /Users/parsa/Desk/projects/university/slmops-project/slmops-thesis/app_projects/app/pyapp/notebooks/d/models/rag_model/model_path/artifacts:/models \
  ghcr.io/ggerganov/llama.cpp:server \
  -m /models/model.gguf)

while ! docker logs $container_id 2>&1 | grep -q "GET /health 127.0.0.1 200"; do
  echo "Loading model and starting server..."
  docker logs --tail 10 $container_id
  sleep 1
done
echo "LlamaCpp server is ready!"

[0m<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
  
May 7, 2025 > 14:59:45 |  serve.servers.llamacpp.serve : 164 |   ❌ ERROR  |  Failed to get status for model rag_model: Model ID 'rag_model' not found  
May 7, 2025 > 14:59:45 |  serve.utils.mlflow.config : 460 |   ❌ ERROR  |  Error getting path for rag_model: No path found for model rag_model  
May 7, 2025 > 15:00:17 |  serve._cli.task : 33 |   ❌ ERROR  |  [32mtask: [serve] echo "Starting LlamaCpp server and waiting for it to be ready..."
[0m[32mtask: [serve] container_id=$(docker run -d \
  --name lmorbits-llamacpp-rag_model \
  -p 8080:8080 \
  -v /Users/parsa/Desk/projects/university/slmops-project/slmops-thesis/app_projects/app/pyapp/notebooks/models/rag_model/model_path/artifacts:/models \
  ghcr.io/ggerganov/llama.cpp:server \
  -m /models/model.gguf)

while ! docker logs $container_id 2>&1 | grep -q "GET /health 127.0.0.1 200"; do
  echo "Loading model and starting server..."
  docker logs --tail 10 $container_id
  sleep 1
done
echo "LlamaCpp server is ready!"

[0mllama_model_loader: - type  f32:   61 tensors
llama_model_loader: - type q5_0:  166 tensors
llama_model_loader: - type q8_0:   15 tensors
llama_model_loader: - type q4_K:   16 tensors
llama_model_loader: - type q6_K:   14 tensors
print_info: file format = GGUF V3 (latest)
print_info: file type   = Q4_K - Medium
print_info: file size   = 98.87 MiB (6.17 BPW) 
load: special tokens cache size = 17
load: token to piece cache size = 0.3170 MB
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
  
May 7, 2025 > 16:21:55 |  serve.servers.llamacpp.serve : 164 |   ❌ ERROR  |  Failed to get status for model rag_model: Model ID 'rag_model' not found  
May 7, 2025 > 16:21:55 |  serve.utils.mlflow.config : 460 |   ❌ ERROR  |  Error getting path for rag_model: No path found for model rag_model  
May 7, 2025 > 16:21:57 |  serve._cli.task : 33 |   ❌ ERROR  |  [32mtask: [serve] echo "Starting LlamaCpp server and waiting for it to be ready..."
[0m[32mtask: [serve] container_id=$(docker run -d \
  --name lmorbits-llamacpp-rag_model \
  -p 8080:8080 \
  -v /Users/parsa/Desk/projects/university/slmops-project/slmops-thesis/app_projects/app/pyapp/notebooks/models/rag_model/model_path/artifacts:/models \
  ghcr.io/ggerganov/llama.cpp:server \
  -m /models/model.gguf)

while ! docker logs $container_id 2>&1 | grep -q "GET /health 127.0.0.1 200"; do
  echo "Loading model and starting server..."
  docker logs --tail 10 $container_id
  sleep 1
done
echo "LlamaCpp server is ready!"

[0mdocker: Error response from daemon: Conflict. The container name "/lmorbits-llamacpp-rag_model" is already in use by container "c7dc2b3387c4e61802e943b8b33baa7d1a678c8b6679041c7560754d869a9ed6". You have to remove (or rename) that container to be able to reuse that name.
See 'docker run --help'.
[31mtask: Failed to run task "serve": exit status 125
[0m  
May 7, 2025 > 16:24:51 |  serve.servers.llamacpp.serve : 164 |   ❌ ERROR  |  Failed to get status for model rag_model: Model ID 'rag_model' not found  
May 7, 2025 > 16:24:51 |  serve._cli.task : 33 |   ❌ ERROR  |  [32mtask: [serve] echo "Starting LlamaCpp server and waiting for it to be ready..."
[0m[32mtask: [serve] container_id=$(docker run -d \
  --name lmorbits-llamacpp-rag_model \
  -p 8080:8080 \
  -v /Users/parsa/Desk/projects/university/slmops-project/slmops-thesis/app_projects/app/pyapp/notebooks/models/rag_model/model_path/artifacts:/models \
  ghcr.io/ggerganov/llama.cpp:server \
  -m /models/model.gguf)

while ! docker logs $container_id 2>&1 | grep -q "GET /health 127.0.0.1 200"; do
  echo "Loading model and starting server..."
  docker logs --tail 10 $container_id
  sleep 1
done
echo "LlamaCpp server is ready!"

[0mdocker: Error response from daemon: Conflict. The container name "/lmorbits-llamacpp-rag_model" is already in use by container "c7dc2b3387c4e61802e943b8b33baa7d1a678c8b6679041c7560754d869a9ed6". You have to remove (or rename) that container to be able to reuse that name.
See 'docker run --help'.
[31mtask: Failed to run task "serve": exit status 125
[0m  
May 7, 2025 > 16:25:30 |  serve.servers.llamacpp.serve : 164 |   ❌ ERROR  |  Failed to get status for model rag_model: Model ID 'rag_model' not found  
May 7, 2025 > 16:25:30 |  serve._cli.task : 33 |   ❌ ERROR  |  [32mtask: [serve] echo "Starting LlamaCpp server and waiting for it to be ready..."
[0m[32mtask: [serve] container_id=$(docker run -d \
  --name lmorbits-llamacpp-rag_model \
  -p 8080:8080 \
  -v /Users/parsa/Desk/projects/university/slmops-project/slmops-thesis/app_projects/app/pyapp/notebooks/models/rag_model/model_path/artifacts:/models \
  ghcr.io/ggerganov/llama.cpp:server \
  -m /models/model.gguf)

while ! docker logs $container_id 2>&1 | grep -q "GET /health 127.0.0.1 200"; do
  echo "Loading model and starting server..."
  docker logs --tail 10 $container_id
  sleep 1
done
echo "LlamaCpp server is ready!"

[0mdocker: Error response from daemon: Conflict. The container name "/lmorbits-llamacpp-rag_model" is already in use by container "c7dc2b3387c4e61802e943b8b33baa7d1a678c8b6679041c7560754d869a9ed6". You have to remove (or rename) that container to be able to reuse that name.
See 'docker run --help'.
[31mtask: Failed to run task "serve": exit status 125
[0m  
May 7, 2025 > 16:31:45 |  serve.servers.llamacpp.serve : 164 |   ❌ ERROR  |  Failed to get status for model rag_model: Model ID 'rag_model' not found  
May 7, 2025 > 16:31:45 |  serve._cli.task : 33 |   ❌ ERROR  |  [32mtask: [serve] echo "Starting LlamaCpp server and waiting for it to be ready..."
[0m[32mtask: [serve] container_id=$(docker run -d \
  --name lmorbits-llamacpp-rag_model \
  -p 8080:8080 \
  -v /Users/parsa/Desk/projects/university/slmops-project/slmops-thesis/app_projects/app/pyapp/notebooks/models/rag_model/model_path/artifacts:/models \
  ghcr.io/ggerganov/llama.cpp:server \
  -m /models/model.gguf)

while ! docker logs $container_id 2>&1 | grep -q "GET /health 127.0.0.1 200"; do
  echo "Loading model and starting server..."
  docker logs --tail 10 $container_id
  sleep 1
done
echo "LlamaCpp server is ready!"

[0mdocker: Error response from daemon: Conflict. The container name "/lmorbits-llamacpp-rag_model" is already in use by container "c7dc2b3387c4e61802e943b8b33baa7d1a678c8b6679041c7560754d869a9ed6". You have to remove (or rename) that container to be able to reuse that name.
See 'docker run --help'.
[31mtask: Failed to run task "serve": exit status 125
[0m  
May 7, 2025 > 16:33:55 |  serve.servers.llamacpp.serve : 164 |   ❌ ERROR  |  Failed to get status for model rag_model: Model ID 'rag_model' not found  
May 7, 2025 > 16:33:55 |  serve._cli.task : 33 |   ❌ ERROR  |  [32mtask: [serve] echo "Starting LlamaCpp server and waiting for it to be ready..."
[0m[32mtask: [serve] container_id=$(docker run -d \
  --name lmorbits-llamacpp-rag_model \
  -p 8080:8080 \
  -v /Users/parsa/Desk/projects/university/slmops-project/slmops-thesis/app_projects/app/pyapp/notebooks/models/rag_model/model_path/artifacts:/models \
  ghcr.io/ggerganov/llama.cpp:server \
  -m /models/model.gguf)

while ! docker logs $container_id 2>&1 | grep -q "GET /health 127.0.0.1 200"; do
  echo "Loading model and starting server..."
  docker logs --tail 10 $container_id
  sleep 1
done
echo "LlamaCpp server is ready!"

[0mdocker: Error response from daemon: Conflict. The container name "/lmorbits-llamacpp-rag_model" is already in use by container "c7dc2b3387c4e61802e943b8b33baa7d1a678c8b6679041c7560754d869a9ed6". You have to remove (or rename) that container to be able to reuse that name.
See 'docker run --help'.
[31mtask: Failed to run task "serve": exit status 125
[0m  
May 7, 2025 > 16:35:19 |  serve.servers.llamacpp.serve : 164 |   ❌ ERROR  |  Failed to get status for model rag_model: Model ID 'rag_model' not found  
May 7, 2025 > 16:35:19 |  serve._cli.task : 33 |   ❌ ERROR  |  [32mtask: [serve] echo "Starting LlamaCpp server and waiting for it to be ready..."
[0m[32mtask: [serve] container_id=$(docker run -d \
  --name lmorbits-llamacpp-rag_model \
  -p 8080:8080 \
  -v /Users/parsa/Desk/projects/university/slmops-project/slmops-thesis/app_projects/app/pyapp/notebooks/models/rag_model/model_path/artifacts:/models \
  ghcr.io/ggerganov/llama.cpp:server \
  -m /models/model.gguf)

while ! docker logs $container_id 2>&1 | grep -q "GET /health 127.0.0.1 200"; do
  echo "Loading model and starting server..."
  docker logs --tail 10 $container_id
  sleep 1
done
echo "LlamaCpp server is ready!"

[0mdocker: Error response from daemon: Conflict. The container name "/lmorbits-llamacpp-rag_model" is already in use by container "c7dc2b3387c4e61802e943b8b33baa7d1a678c8b6679041c7560754d869a9ed6". You have to remove (or rename) that container to be able to reuse that name.
See 'docker run --help'.
[31mtask: Failed to run task "serve": exit status 125
[0m  
May 7, 2025 > 16:35:50 |  serve.servers.llamacpp.serve : 164 |   ❌ ERROR  |  Failed to get status for model rag_model: Model ID 'rag_model' not found  
May 7, 2025 > 16:35:50 |  serve._cli.task : 33 |   ❌ ERROR  |  [32mtask: [serve] echo "Starting LlamaCpp server and waiting for it to be ready..."
[0m[32mtask: [serve] container_id=$(docker run -d \
  --name lmorbits-llamacpp-rag_model \
  -p 8080:8080 \
  -v /Users/parsa/Desk/projects/university/slmops-project/slmops-thesis/app_projects/app/pyapp/notebooks/models/rag_model/model_path/artifacts:/models \
  ghcr.io/ggerganov/llama.cpp:server \
  -m /models/model.gguf)

while ! docker logs $container_id 2>&1 | grep -q "GET /health 127.0.0.1 200"; do
  echo "Loading model and starting server..."
  docker logs --tail 10 $container_id
  sleep 1
done
echo "LlamaCpp server is ready!"

[0mdocker: Error response from daemon: Conflict. The container name "/lmorbits-llamacpp-rag_model" is already in use by container "c7dc2b3387c4e61802e943b8b33baa7d1a678c8b6679041c7560754d869a9ed6". You have to remove (or rename) that container to be able to reuse that name.
See 'docker run --help'.
[31mtask: Failed to run task "serve": exit status 125
[0m  
May 7, 2025 > 16:48:22 |  serve.servers.llamacpp.serve : 164 |   ❌ ERROR  |  Failed to get status for model rag_model: Model ID 'rag_model' not found  
May 7, 2025 > 16:48:22 |  serve._cli.task : 33 |   ❌ ERROR  |  [32mtask: [serve] echo "Starting LlamaCpp server and waiting for it to be ready..."
[0m[32mtask: [serve] container_id=$(docker run -d \
  --name lmorbits-llamacpp-rag_model \
  -p 8080:8080 \
  -v /Users/parsa/Desk/projects/university/slmops-project/slmops-thesis/app_projects/app/pyapp/notebooks/models/rag_model/model_path/artifacts:/models \
  ghcr.io/ggerganov/llama.cpp:server \
  -m /models/model.gguf)

while ! docker logs $container_id 2>&1 | grep -q "GET /health 127.0.0.1 200"; do
  echo "Loading model and starting server..."
  docker logs --tail 10 $container_id
  sleep 1
done
echo "LlamaCpp server is ready!"

[0mdocker: Error response from daemon: Conflict. The container name "/lmorbits-llamacpp-rag_model" is already in use by container "c7dc2b3387c4e61802e943b8b33baa7d1a678c8b6679041c7560754d869a9ed6". You have to remove (or rename) that container to be able to reuse that name.
See 'docker run --help'.
[31mtask: Failed to run task "serve": exit status 125
[0m  
May 7, 2025 > 16:59:11 |  serve.servers.llamacpp.serve : 164 |   ❌ ERROR  |  Failed to get status for model rag_model: Model ID 'rag_model' not found  
May 7, 2025 > 16:59:11 |  serve._cli.task : 33 |   ❌ ERROR  |  [32mtask: [serve] echo "Starting LlamaCpp server and waiting for it to be ready..."
[0m[32mtask: [serve] container_id=$(docker run -d \
  --name lmorbits-llamacpp-rag_model \
  -p 8080:8080 \
  -v /Users/parsa/Desk/projects/university/slmops-project/slmops-thesis/app_projects/app/pyapp/notebooks/models/rag_model/model_path/artifacts:/models \
  ghcr.io/ggerganov/llama.cpp:server \
  -m /models/model.gguf)

while ! docker logs $container_id 2>&1 | grep -q "GET /health 127.0.0.1 200"; do
  echo "Loading model and starting server..."
  docker logs --tail 10 $container_id
  sleep 1
done
echo "LlamaCpp server is ready!"

[0mdocker: Error response from daemon: Conflict. The container name "/lmorbits-llamacpp-rag_model" is already in use by container "c7dc2b3387c4e61802e943b8b33baa7d1a678c8b6679041c7560754d869a9ed6". You have to remove (or rename) that container to be able to reuse that name.
See 'docker run --help'.
[31mtask: Failed to run task "serve": exit status 125
[0m  
May 7, 2025 > 17:03:09 |  serve.servers.llamacpp.serve : 164 |   ❌ ERROR  |  Failed to get status for model rag_model: Model ID 'rag_model' not found  
May 7, 2025 > 17:03:09 |  serve._cli.task : 33 |   ❌ ERROR  |  [32mtask: [serve] echo "Starting LlamaCpp server and waiting for it to be ready..."
[0m[32mtask: [serve] container_id=$(docker run -d \
  --name lmorbits-llamacpp-rag_model \
  -p 8080:8080 \
  -v /Users/parsa/Desk/projects/university/slmops-project/slmops-thesis/app_projects/app/pyapp/notebooks/models/rag_model/model_path/artifacts:/models \
  ghcr.io/ggerganov/llama.cpp:server \
  -m /models/model.gguf)

while ! docker logs $container_id 2>&1 | grep -q "GET /health 127.0.0.1 200"; do
  echo "Loading model and starting server..."
  docker logs --tail 10 $container_id
  sleep 1
done
echo "LlamaCpp server is ready!"

[0mdocker: Error response from daemon: Conflict. The container name "/lmorbits-llamacpp-rag_model" is already in use by container "c7dc2b3387c4e61802e943b8b33baa7d1a678c8b6679041c7560754d869a9ed6". You have to remove (or rename) that container to be able to reuse that name.
See 'docker run --help'.
[31mtask: Failed to run task "serve": exit status 125
[0m  
May 8, 2025 > 10:33:20 |  taskpy.main : 32 |   ❌ ERROR  |  [32mtask: [status] docker ps | grep lmorbits-obeservation | wc -l
[0m  
May 8, 2025 > 10:34:27 |  serve.servers.llamacpp.serve : 164 |   ❌ ERROR  |  Failed to get status for model rag_model: Model ID 'rag_model' not found  
May 8, 2025 > 10:34:28 |  serve.utils.mlflow.config : 460 |   ❌ ERROR  |  Error getting path for rag_model: No path found for model rag_model  
May 8, 2025 > 10:35:00 |  serve._cli.task : 33 |   ❌ ERROR  |  [32mtask: [serve] echo "Starting LlamaCpp server and waiting for it to be ready..."
[0m[32mtask: [serve] container_id=$(docker run -d \
  --name lmorbits-llamacpp-rag_model \
  -p 8080:8080 \
  -v /Users/parsa/Desk/projects/university/slmops-project/slmops-thesis/app_projects/app/pyapp/notebooks/models/rag_model/model_path/artifacts:/models \
  ghcr.io/ggerganov/llama.cpp:server \
  -m /models/model.gguf)

while ! docker logs $container_id 2>&1 | grep -q "GET /health 127.0.0.1 200"; do
  echo "Loading model and starting server..."
  docker logs --tail 10 $container_id
  sleep 1
done
echo "LlamaCpp server is ready!"

[0m<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
  
May 8, 2025 > 11:12:22 |  pyapp.observation.instance : 97 |   ❌ ERROR  |  Error in phoenix observation: name 'a' is not defined  
May 8, 2025 > 11:12:22 |  taskpy.main : 32 |   ❌ ERROR  |  [32mtask: [status] docker ps | grep lmorbits-obeservation | wc -l
[0m  
May 8, 2025 > 11:12:23 |  serve.servers.llamacpp.serve : 164 |   ❌ ERROR  |  Failed to get status for model rag_model: Model ID 'rag_model' not found  
May 8, 2025 > 11:12:23 |  serve._cli.task : 33 |   ❌ ERROR  |  [32mtask: [serve] echo "Starting LlamaCpp server and waiting for it to be ready..."
[0m[32mtask: [serve] container_id=$(docker run -d \
  --name lmorbits-llamacpp-rag_model \
  -p 8080:8080 \
  -v /Users/parsa/Desk/projects/university/slmops-project/slmops-thesis/app_projects/app/pyapp/notebooks/models/rag_model/model_path/artifacts:/models \
  ghcr.io/ggerganov/llama.cpp:server \
  -m /models/model.gguf)

while ! docker logs $container_id 2>&1 | grep -q "GET /health 127.0.0.1 200"; do
  echo "Loading model and starting server..."
  docker logs --tail 10 $container_id
  sleep 1
done
echo "LlamaCpp server is ready!"

[0mdocker: Error response from daemon: Conflict. The container name "/lmorbits-llamacpp-rag_model" is already in use by container "1c417611e9797bbae3868a17c1a7ea12d0d9a3529ea090c98d679ee3f4cf5075". You have to remove (or rename) that container to be able to reuse that name.
See 'docker run --help'.
[31mtask: Failed to run task "serve": exit status 125
[0m  
May 8, 2025 > 11:13:36 |  pyapp.observation.instance : 97 |   ❌ ERROR  |  Error in phoenix observation: name 'a' is not defined  
May 8, 2025 > 11:13:36 |  taskpy.main : 32 |   ❌ ERROR  |  [32mtask: [status] docker ps | grep lmorbits-obeservation | wc -l
[0m  
May 8, 2025 > 11:13:45 |  pyapp.observation.instance : 97 |   ❌ ERROR  |  Error in phoenix observation: name 'a' is not defined  
May 8, 2025 > 11:13:45 |  taskpy.main : 32 |   ❌ ERROR  |  [32mtask: [status] docker ps | grep lmorbits-obeservation | wc -l
[0m  
May 8, 2025 > 11:13:46 |  serve.servers.llamacpp.serve : 164 |   ❌ ERROR  |  Failed to get status for model rag_model: Model ID 'rag_model' not found  
May 8, 2025 > 11:13:46 |  serve._cli.task : 33 |   ❌ ERROR  |  [32mtask: [serve] echo "Starting LlamaCpp server and waiting for it to be ready..."
[0m[32mtask: [serve] container_id=$(docker run -d \
  --name lmorbits-llamacpp-rag_model \
  -p 8080:8080 \
  -v /Users/parsa/Desk/projects/university/slmops-project/slmops-thesis/app_projects/app/pyapp/notebooks/models/rag_model/model_path/artifacts:/models \
  ghcr.io/ggerganov/llama.cpp:server \
  -m /models/model.gguf)

while ! docker logs $container_id 2>&1 | grep -q "GET /health 127.0.0.1 200"; do
  echo "Loading model and starting server..."
  docker logs --tail 10 $container_id
  sleep 1
done
echo "LlamaCpp server is ready!"

[0mdocker: Error response from daemon: Conflict. The container name "/lmorbits-llamacpp-rag_model" is already in use by container "1c417611e9797bbae3868a17c1a7ea12d0d9a3529ea090c98d679ee3f4cf5075". You have to remove (or rename) that container to be able to reuse that name.
See 'docker run --help'.
[31mtask: Failed to run task "serve": exit status 125
[0m  
May 8, 2025 > 11:15:23 |  taskpy.main : 32 |   ❌ ERROR  |  [32mtask: [status] docker ps | grep lmorbits-obeservation | wc -l
[0m  
May 8, 2025 > 11:15:23 |  serve.servers.llamacpp.serve : 164 |   ❌ ERROR  |  Failed to get status for model rag_model: Model ID 'rag_model' not found  
May 8, 2025 > 11:15:23 |  serve._cli.task : 33 |   ❌ ERROR  |  [32mtask: [serve] echo "Starting LlamaCpp server and waiting for it to be ready..."
[0m[32mtask: [serve] container_id=$(docker run -d \
  --name lmorbits-llamacpp-rag_model \
  -p 8080:8080 \
  -v /Users/parsa/Desk/projects/university/slmops-project/slmops-thesis/app_projects/app/pyapp/notebooks/models/rag_model/model_path/artifacts:/models \
  ghcr.io/ggerganov/llama.cpp:server \
  -m /models/model.gguf)

while ! docker logs $container_id 2>&1 | grep -q "GET /health 127.0.0.1 200"; do
  echo "Loading model and starting server..."
  docker logs --tail 10 $container_id
  sleep 1
done
echo "LlamaCpp server is ready!"

[0mdocker: Error response from daemon: Conflict. The container name "/lmorbits-llamacpp-rag_model" is already in use by container "1c417611e9797bbae3868a17c1a7ea12d0d9a3529ea090c98d679ee3f4cf5075". You have to remove (or rename) that container to be able to reuse that name.
See 'docker run --help'.
[31mtask: Failed to run task "serve": exit status 125
[0m  
May 8, 2025 > 11:15:57 |  taskpy.main : 32 |   ❌ ERROR  |  [32mtask: [status] docker ps | grep lmorbits-obeservation | wc -l
[0m  
May 8, 2025 > 11:15:58 |  serve.servers.llamacpp.serve : 164 |   ❌ ERROR  |  Failed to get status for model rag_model: Model ID 'rag_model' not found  
May 8, 2025 > 11:15:58 |  serve._cli.task : 33 |   ❌ ERROR  |  [32mtask: [serve] echo "Starting LlamaCpp server and waiting for it to be ready..."
[0m[32mtask: [serve] container_id=$(docker run -d \
  --name lmorbits-llamacpp-rag_model \
  -p 8080:8080 \
  -v /Users/parsa/Desk/projects/university/slmops-project/slmops-thesis/app_projects/app/pyapp/notebooks/models/rag_model/model_path/artifacts:/models \
  ghcr.io/ggerganov/llama.cpp:server \
  -m /models/model.gguf)

while ! docker logs $container_id 2>&1 | grep -q "GET /health 127.0.0.1 200"; do
  echo "Loading model and starting server..."
  docker logs --tail 10 $container_id
  sleep 1
done
echo "LlamaCpp server is ready!"

[0mdocker: Error response from daemon: Conflict. The container name "/lmorbits-llamacpp-rag_model" is already in use by container "1c417611e9797bbae3868a17c1a7ea12d0d9a3529ea090c98d679ee3f4cf5075". You have to remove (or rename) that container to be able to reuse that name.
See 'docker run --help'.
[31mtask: Failed to run task "serve": exit status 125
[0m  
May 8, 2025 > 11:48:48 |  taskpy.main : 32 |   ❌ ERROR  |  [32mtask: [status] docker ps | grep lmorbits-obeservation | wc -l
[0m  
May 8, 2025 > 11:48:49 |  serve.servers.llamacpp.serve : 164 |   ❌ ERROR  |  Failed to get status for model rag_model: Model ID 'rag_model' not found  
May 8, 2025 > 11:48:49 |  serve._cli.task : 33 |   ❌ ERROR  |  [32mtask: [serve] echo "Starting LlamaCpp server and waiting for it to be ready..."
[0m[32mtask: [serve] container_id=$(docker run -d \
  --name lmorbits-llamacpp-rag_model \
  -p 8080:8080 \
  -v /Users/parsa/Desk/projects/university/slmops-project/slmops-thesis/app_projects/app/pyapp/notebooks/models/rag_model/model_path/artifacts:/models \
  ghcr.io/ggerganov/llama.cpp:server \
  -m /models/model.gguf)

while ! docker logs $container_id 2>&1 | grep -q "GET /health 127.0.0.1 200"; do
  echo "Loading model and starting server..."
  docker logs --tail 10 $container_id
  sleep 1
done
echo "LlamaCpp server is ready!"

[0mdocker: Error response from daemon: Conflict. The container name "/lmorbits-llamacpp-rag_model" is already in use by container "1c417611e9797bbae3868a17c1a7ea12d0d9a3529ea090c98d679ee3f4cf5075". You have to remove (or rename) that container to be able to reuse that name.
See 'docker run --help'.
[31mtask: Failed to run task "serve": exit status 125
[0m  
May 8, 2025 > 11:55:04 |  taskpy.main : 32 |   ❌ ERROR  |  [32mtask: [status] docker ps | grep lmorbits-obeservation | wc -l
[0m  
May 8, 2025 > 11:55:04 |  serve.servers.llamacpp.serve : 164 |   ❌ ERROR  |  Failed to get status for model rag_model: Model ID 'rag_model' not found  
May 8, 2025 > 11:55:05 |  serve._cli.task : 33 |   ❌ ERROR  |  [32mtask: [serve] echo "Starting LlamaCpp server and waiting for it to be ready..."
[0m[32mtask: [serve] container_id=$(docker run -d \
  --name lmorbits-llamacpp-rag_model \
  -p 8080:8080 \
  -v /Users/parsa/Desk/projects/university/slmops-project/slmops-thesis/app_projects/app/pyapp/notebooks/models/rag_model/model_path/artifacts:/models \
  ghcr.io/ggerganov/llama.cpp:server \
  -m /models/model.gguf)

while ! docker logs $container_id 2>&1 | grep -q "GET /health 127.0.0.1 200"; do
  echo "Loading model and starting server..."
  docker logs --tail 10 $container_id
  sleep 1
done
echo "LlamaCpp server is ready!"

[0mdocker: Error response from daemon: Conflict. The container name "/lmorbits-llamacpp-rag_model" is already in use by container "1c417611e9797bbae3868a17c1a7ea12d0d9a3529ea090c98d679ee3f4cf5075". You have to remove (or rename) that container to be able to reuse that name.
See 'docker run --help'.
[31mtask: Failed to run task "serve": exit status 125
[0m  
May 8, 2025 > 12:02:57 |  taskpy.main : 32 |   ❌ ERROR  |  [32mtask: [status] docker ps | grep lmorbits-obeservation | wc -l
[0m  
May 8, 2025 > 12:02:57 |  serve.servers.llamacpp.serve : 164 |   ❌ ERROR  |  Failed to get status for model rag_model: Model ID 'rag_model' not found  
May 8, 2025 > 12:02:57 |  serve._cli.task : 33 |   ❌ ERROR  |  [32mtask: [serve] echo "Starting LlamaCpp server and waiting for it to be ready..."
[0m[32mtask: [serve] container_id=$(docker run -d \
  --name lmorbits-llamacpp-rag_model \
  -p 8080:8080 \
  -v /Users/parsa/Desk/projects/university/slmops-project/slmops-thesis/app_projects/app/pyapp/notebooks/models/rag_model/model_path/artifacts:/models \
  ghcr.io/ggerganov/llama.cpp:server \
  -m /models/model.gguf)

while ! docker logs $container_id 2>&1 | grep -q "GET /health 127.0.0.1 200"; do
  echo "Loading model and starting server..."
  docker logs --tail 10 $container_id
  sleep 1
done
echo "LlamaCpp server is ready!"

[0mdocker: Error response from daemon: Conflict. The container name "/lmorbits-llamacpp-rag_model" is already in use by container "1c417611e9797bbae3868a17c1a7ea12d0d9a3529ea090c98d679ee3f4cf5075". You have to remove (or rename) that container to be able to reuse that name.
See 'docker run --help'.
[31mtask: Failed to run task "serve": exit status 125
[0m  
May 8, 2025 > 12:04:18 |  taskpy.main : 32 |   ❌ ERROR  |  [32mtask: [status] docker ps | grep lmorbits-obeservation | wc -l
[0m  
May 8, 2025 > 12:04:19 |  serve.servers.llamacpp.serve : 164 |   ❌ ERROR  |  Failed to get status for model rag_model: Model ID 'rag_model' not found  
May 8, 2025 > 12:04:19 |  serve._cli.task : 33 |   ❌ ERROR  |  [32mtask: [serve] echo "Starting LlamaCpp server and waiting for it to be ready..."
[0m[32mtask: [serve] container_id=$(docker run -d \
  --name lmorbits-llamacpp-rag_model \
  -p 8080:8080 \
  -v /Users/parsa/Desk/projects/university/slmops-project/slmops-thesis/app_projects/app/pyapp/notebooks/models/rag_model/model_path/artifacts:/models \
  ghcr.io/ggerganov/llama.cpp:server \
  -m /models/model.gguf)

while ! docker logs $container_id 2>&1 | grep -q "GET /health 127.0.0.1 200"; do
  echo "Loading model and starting server..."
  docker logs --tail 10 $container_id
  sleep 1
done
echo "LlamaCpp server is ready!"

[0mdocker: Error response from daemon: Conflict. The container name "/lmorbits-llamacpp-rag_model" is already in use by container "1c417611e9797bbae3868a17c1a7ea12d0d9a3529ea090c98d679ee3f4cf5075". You have to remove (or rename) that container to be able to reuse that name.
See 'docker run --help'.
[31mtask: Failed to run task "serve": exit status 125
[0m  
May 8, 2025 > 12:06:06 |  taskpy.main : 32 |   ❌ ERROR  |  [32mtask: [status] docker ps | grep lmorbits-obeservation | wc -l
[0m  
May 8, 2025 > 12:06:07 |  serve.servers.llamacpp.serve : 164 |   ❌ ERROR  |  Failed to get status for model rag_model: Model ID 'rag_model' not found  
May 8, 2025 > 12:06:07 |  serve._cli.task : 33 |   ❌ ERROR  |  [32mtask: [serve] echo "Starting LlamaCpp server and waiting for it to be ready..."
[0m[32mtask: [serve] container_id=$(docker run -d \
  --name lmorbits-llamacpp-rag_model \
  -p 8080:8080 \
  -v /Users/parsa/Desk/projects/university/slmops-project/slmops-thesis/app_projects/app/pyapp/notebooks/models/rag_model/model_path/artifacts:/models \
  ghcr.io/ggerganov/llama.cpp:server \
  -m /models/model.gguf)

while ! docker logs $container_id 2>&1 | grep -q "GET /health 127.0.0.1 200"; do
  echo "Loading model and starting server..."
  docker logs --tail 10 $container_id
  sleep 1
done
echo "LlamaCpp server is ready!"

[0mdocker: Error response from daemon: Conflict. The container name "/lmorbits-llamacpp-rag_model" is already in use by container "1c417611e9797bbae3868a17c1a7ea12d0d9a3529ea090c98d679ee3f4cf5075". You have to remove (or rename) that container to be able to reuse that name.
See 'docker run --help'.
[31mtask: Failed to run task "serve": exit status 125
[0m  
May 8, 2025 > 13:06:24 |  taskpy.main : 32 |   ❌ ERROR  |  [32mtask: [status] docker ps | grep lmorbits-obeservation | wc -l
[0m  
May 8, 2025 > 13:06:25 |  serve.servers.llamacpp.serve : 164 |   ❌ ERROR  |  Failed to get status for model rag_model: Model ID 'rag_model' not found  
May 8, 2025 > 13:06:25 |  serve._cli.task : 33 |   ❌ ERROR  |  [32mtask: [serve] echo "Starting LlamaCpp server and waiting for it to be ready..."
[0m[32mtask: [serve] container_id=$(docker run -d \
  --name lmorbits-llamacpp-rag_model \
  -p 8080:8080 \
  -v /Users/parsa/Desk/projects/university/slmops-project/slmops-thesis/app_projects/app/pyapp/notebooks/models/rag_model/model_path/artifacts:/models \
  ghcr.io/ggerganov/llama.cpp:server \
  -m /models/model.gguf)

while ! docker logs $container_id 2>&1 | grep -q "GET /health 127.0.0.1 200"; do
  echo "Loading model and starting server..."
  docker logs --tail 10 $container_id
  sleep 1
done
echo "LlamaCpp server is ready!"

[0mdocker: Error response from daemon: Conflict. The container name "/lmorbits-llamacpp-rag_model" is already in use by container "1c417611e9797bbae3868a17c1a7ea12d0d9a3529ea090c98d679ee3f4cf5075". You have to remove (or rename) that container to be able to reuse that name.
See 'docker run --help'.
[31mtask: Failed to run task "serve": exit status 125
[0m  
May 8, 2025 > 13:09:03 |  taskpy.main : 32 |   ❌ ERROR  |  [32mtask: [status] docker ps | grep lmorbits-obeservation | wc -l
[0m  
May 8, 2025 > 13:09:03 |  serve.servers.llamacpp.serve : 164 |   ❌ ERROR  |  Failed to get status for model rag_model: Model ID 'rag_model' not found  
May 8, 2025 > 13:09:03 |  serve._cli.task : 33 |   ❌ ERROR  |  [32mtask: [serve] echo "Starting LlamaCpp server and waiting for it to be ready..."
[0m[32mtask: [serve] container_id=$(docker run -d \
  --name lmorbits-llamacpp-rag_model \
  -p 8080:8080 \
  -v /Users/parsa/Desk/projects/university/slmops-project/slmops-thesis/app_projects/app/pyapp/notebooks/models/rag_model/model_path/artifacts:/models \
  ghcr.io/ggerganov/llama.cpp:server \
  -m /models/model.gguf)

while ! docker logs $container_id 2>&1 | grep -q "GET /health 127.0.0.1 200"; do
  echo "Loading model and starting server..."
  docker logs --tail 10 $container_id
  sleep 1
done
echo "LlamaCpp server is ready!"

[0mdocker: Error response from daemon: Conflict. The container name "/lmorbits-llamacpp-rag_model" is already in use by container "1c417611e9797bbae3868a17c1a7ea12d0d9a3529ea090c98d679ee3f4cf5075". You have to remove (or rename) that container to be able to reuse that name.
See 'docker run --help'.
[31mtask: Failed to run task "serve": exit status 125
[0m  
May 8, 2025 > 13:11:16 |  taskpy.main : 32 |   ❌ ERROR  |  [32mtask: [status] docker ps | grep lmorbits-obeservation | wc -l
[0m  
May 8, 2025 > 13:11:17 |  serve.servers.llamacpp.serve : 164 |   ❌ ERROR  |  Failed to get status for model rag_model: Model ID 'rag_model' not found  
May 8, 2025 > 13:11:17 |  serve._cli.task : 33 |   ❌ ERROR  |  [32mtask: [serve] echo "Starting LlamaCpp server and waiting for it to be ready..."
[0m[32mtask: [serve] container_id=$(docker run -d \
  --name lmorbits-llamacpp-rag_model \
  -p 8080:8080 \
  -v /Users/parsa/Desk/projects/university/slmops-project/slmops-thesis/app_projects/app/pyapp/notebooks/models/rag_model/model_path/artifacts:/models \
  ghcr.io/ggerganov/llama.cpp:server \
  -m /models/model.gguf)

while ! docker logs $container_id 2>&1 | grep -q "GET /health 127.0.0.1 200"; do
  echo "Loading model and starting server..."
  docker logs --tail 10 $container_id
  sleep 1
done
echo "LlamaCpp server is ready!"

[0mdocker: Error response from daemon: Conflict. The container name "/lmorbits-llamacpp-rag_model" is already in use by container "1c417611e9797bbae3868a17c1a7ea12d0d9a3529ea090c98d679ee3f4cf5075". You have to remove (or rename) that container to be able to reuse that name.
See 'docker run --help'.
[31mtask: Failed to run task "serve": exit status 125
[0m  
May 8, 2025 > 13:12:00 |  taskpy.main : 32 |   ❌ ERROR  |  [32mtask: [status] docker ps | grep lmorbits-obeservation | wc -l
[0m  
May 8, 2025 > 13:12:01 |  serve.servers.llamacpp.serve : 164 |   ❌ ERROR  |  Failed to get status for model rag_model: Model ID 'rag_model' not found  
May 8, 2025 > 13:12:01 |  serve._cli.task : 33 |   ❌ ERROR  |  [32mtask: [serve] echo "Starting LlamaCpp server and waiting for it to be ready..."
[0m[32mtask: [serve] container_id=$(docker run -d \
  --name lmorbits-llamacpp-rag_model \
  -p 8080:8080 \
  -v /Users/parsa/Desk/projects/university/slmops-project/slmops-thesis/app_projects/app/pyapp/notebooks/models/rag_model/model_path/artifacts:/models \
  ghcr.io/ggerganov/llama.cpp:server \
  -m /models/model.gguf)

while ! docker logs $container_id 2>&1 | grep -q "GET /health 127.0.0.1 200"; do
  echo "Loading model and starting server..."
  docker logs --tail 10 $container_id
  sleep 1
done
echo "LlamaCpp server is ready!"

[0mdocker: Error response from daemon: Conflict. The container name "/lmorbits-llamacpp-rag_model" is already in use by container "1c417611e9797bbae3868a17c1a7ea12d0d9a3529ea090c98d679ee3f4cf5075". You have to remove (or rename) that container to be able to reuse that name.
See 'docker run --help'.
[31mtask: Failed to run task "serve": exit status 125
[0m  
May 8, 2025 > 13:14:00 |  taskpy.main : 32 |   ❌ ERROR  |  [32mtask: [status] docker ps | grep lmorbits-obeservation | wc -l
[0m  
May 8, 2025 > 13:14:30 |  taskpy.main : 32 |   ❌ ERROR  |  [32mtask: [status] docker ps | grep lmorbits-obeservation | wc -l
[0m  
May 8, 2025 > 13:17:40 |  taskpy.main : 32 |   ❌ ERROR  |  [32mtask: [status] docker ps | grep lmorbits-obeservation | wc -l
[0m  
May 8, 2025 > 13:17:41 |  serve.servers.llamacpp.serve : 164 |   ❌ ERROR  |  Failed to get status for model rag_model: Model ID 'rag_model' not found  
May 8, 2025 > 13:17:41 |  serve._cli.task : 33 |   ❌ ERROR  |  [32mtask: [serve] echo "Starting LlamaCpp server and waiting for it to be ready..."
[0m[32mtask: [serve] container_id=$(docker run -d \
  --name lmorbits-llamacpp-rag_model \
  -p 8080:8080 \
  -v /Users/parsa/Desk/projects/university/slmops-project/slmops-thesis/app_projects/app/pyapp/notebooks/models/rag_model/model_path/artifacts:/models \
  ghcr.io/ggerganov/llama.cpp:server \
  -m /models/model.gguf)

while ! docker logs $container_id 2>&1 | grep -q "GET /health 127.0.0.1 200"; do
  echo "Loading model and starting server..."
  docker logs --tail 10 $container_id
  sleep 1
done
echo "LlamaCpp server is ready!"

[0mdocker: Error response from daemon: Conflict. The container name "/lmorbits-llamacpp-rag_model" is already in use by container "1c417611e9797bbae3868a17c1a7ea12d0d9a3529ea090c98d679ee3f4cf5075". You have to remove (or rename) that container to be able to reuse that name.
See 'docker run --help'.
[31mtask: Failed to run task "serve": exit status 125
[0m  
May 8, 2025 > 13:18:19 |  taskpy.main : 32 |   ❌ ERROR  |  [32mtask: [status] docker ps | grep lmorbits-obeservation | wc -l
[0m  
May 8, 2025 > 13:18:20 |  serve.servers.llamacpp.serve : 164 |   ❌ ERROR  |  Failed to get status for model rag_model: Model ID 'rag_model' not found  
May 8, 2025 > 13:18:20 |  serve._cli.task : 33 |   ❌ ERROR  |  [32mtask: [serve] echo "Starting LlamaCpp server and waiting for it to be ready..."
[0m[32mtask: [serve] container_id=$(docker run -d \
  --name lmorbits-llamacpp-rag_model \
  -p 8080:8080 \
  -v /Users/parsa/Desk/projects/university/slmops-project/slmops-thesis/app_projects/app/pyapp/notebooks/models/rag_model/model_path/artifacts:/models \
  ghcr.io/ggerganov/llama.cpp:server \
  -m /models/model.gguf)

while ! docker logs $container_id 2>&1 | grep -q "GET /health 127.0.0.1 200"; do
  echo "Loading model and starting server..."
  docker logs --tail 10 $container_id
  sleep 1
done
echo "LlamaCpp server is ready!"

[0mdocker: Error response from daemon: Conflict. The container name "/lmorbits-llamacpp-rag_model" is already in use by container "1c417611e9797bbae3868a17c1a7ea12d0d9a3529ea090c98d679ee3f4cf5075". You have to remove (or rename) that container to be able to reuse that name.
See 'docker run --help'.
[31mtask: Failed to run task "serve": exit status 125
[0m  
May 8, 2025 > 13:23:43 |  taskpy.main : 32 |   ❌ ERROR  |  [32mtask: [status] docker ps | grep lmorbits-obeservation | wc -l
[0m  
May 8, 2025 > 13:23:43 |  serve.servers.llamacpp.serve : 164 |   ❌ ERROR  |  Failed to get status for model rag_model: Model ID 'rag_model' not found  
May 8, 2025 > 13:23:43 |  serve._cli.task : 33 |   ❌ ERROR  |  [32mtask: [serve] echo "Starting LlamaCpp server and waiting for it to be ready..."
[0m[32mtask: [serve] container_id=$(docker run -d \
  --name lmorbits-llamacpp-rag_model \
  -p 8080:8080 \
  -v /Users/parsa/Desk/projects/university/slmops-project/slmops-thesis/app_projects/app/pyapp/notebooks/models/rag_model/model_path/artifacts:/models \
  ghcr.io/ggerganov/llama.cpp:server \
  -m /models/model.gguf)

while ! docker logs $container_id 2>&1 | grep -q "GET /health 127.0.0.1 200"; do
  echo "Loading model and starting server..."
  docker logs --tail 10 $container_id
  sleep 1
done
echo "LlamaCpp server is ready!"

[0mdocker: Error response from daemon: Conflict. The container name "/lmorbits-llamacpp-rag_model" is already in use by container "1c417611e9797bbae3868a17c1a7ea12d0d9a3529ea090c98d679ee3f4cf5075". You have to remove (or rename) that container to be able to reuse that name.
See 'docker run --help'.
[31mtask: Failed to run task "serve": exit status 125
[0m  
May 8, 2025 > 13:25:49 |  taskpy.main : 32 |   ❌ ERROR  |  [32mtask: [status] docker ps | grep lmorbits-obeservation | wc -l
[0m  
May 8, 2025 > 13:25:50 |  serve.servers.llamacpp.serve : 164 |   ❌ ERROR  |  Failed to get status for model rag_model: Model ID 'rag_model' not found  
May 8, 2025 > 13:25:50 |  serve._cli.task : 33 |   ❌ ERROR  |  [32mtask: [serve] echo "Starting LlamaCpp server and waiting for it to be ready..."
[0m[32mtask: [serve] container_id=$(docker run -d \
  --name lmorbits-llamacpp-rag_model \
  -p 8080:8080 \
  -v /Users/parsa/Desk/projects/university/slmops-project/slmops-thesis/app_projects/app/pyapp/notebooks/models/rag_model/model_path/artifacts:/models \
  ghcr.io/ggerganov/llama.cpp:server \
  -m /models/model.gguf)

while ! docker logs $container_id 2>&1 | grep -q "GET /health 127.0.0.1 200"; do
  echo "Loading model and starting server..."
  docker logs --tail 10 $container_id
  sleep 1
done
echo "LlamaCpp server is ready!"

[0mdocker: Error response from daemon: Conflict. The container name "/lmorbits-llamacpp-rag_model" is already in use by container "1c417611e9797bbae3868a17c1a7ea12d0d9a3529ea090c98d679ee3f4cf5075". You have to remove (or rename) that container to be able to reuse that name.
See 'docker run --help'.
[31mtask: Failed to run task "serve": exit status 125
[0m  
May 8, 2025 > 13:29:58 |  taskpy.main : 32 |   ❌ ERROR  |  [32mtask: [status] docker ps | grep lmorbits-obeservation | wc -l
[0m  
May 8, 2025 > 13:29:59 |  serve.servers.llamacpp.serve : 164 |   ❌ ERROR  |  Failed to get status for model rag_model: Model ID 'rag_model' not found  
May 8, 2025 > 13:29:59 |  serve._cli.task : 33 |   ❌ ERROR  |  [32mtask: [serve] echo "Starting LlamaCpp server and waiting for it to be ready..."
[0m[32mtask: [serve] container_id=$(docker run -d \
  --name lmorbits-llamacpp-rag_model \
  -p 8080:8080 \
  -v /Users/parsa/Desk/projects/university/slmops-project/slmops-thesis/app_projects/app/pyapp/notebooks/models/rag_model/model_path/artifacts:/models \
  ghcr.io/ggerganov/llama.cpp:server \
  -m /models/model.gguf)

while ! docker logs $container_id 2>&1 | grep -q "GET /health 127.0.0.1 200"; do
  echo "Loading model and starting server..."
  docker logs --tail 10 $container_id
  sleep 1
done
echo "LlamaCpp server is ready!"

[0mdocker: Error response from daemon: Conflict. The container name "/lmorbits-llamacpp-rag_model" is already in use by container "1c417611e9797bbae3868a17c1a7ea12d0d9a3529ea090c98d679ee3f4cf5075". You have to remove (or rename) that container to be able to reuse that name.
See 'docker run --help'.
[31mtask: Failed to run task "serve": exit status 125
[0m  
May 8, 2025 > 17:16:27 |  serve.servers.llamacpp.serve : 164 |   ❌ ERROR  |  Failed to get status for model r: Model ID 'r' not found  
May 8, 2025 > 17:16:27 |  serve.utils.mlflow.config : 246 |   ❌ ERROR  |  MLflow error checking r version: INVALID_PARAMETER_VALUE: Registered model alias champion not found.  
May 8, 2025 > 17:16:27 |  serve.utils.mlflow.config : 208 |   ❌ ERROR  |  MLflow error while adding model r: INVALID_PARAMETER_VALUE: Registered model alias champion not found.  
May 8, 2025 > 17:18:23 |  serve.servers.llamacpp.serve : 164 |   ❌ ERROR  |  Failed to get status for model rag_model: Model ID 'rag_model' not found  
May 8, 2025 > 17:18:23 |  serve.utils.mlflow.config : 460 |   ❌ ERROR  |  Error getting path for rag_model: No path found for model rag_model  
May 8, 2025 > 17:18:56 |  serve._cli.task : 33 |   ❌ ERROR  |  task: [serve] echo "Starting LlamaCpp server and waiting for it to be ready..."
task: [serve] container_id=$(docker run -d \
  --name lmorbits-llamacpp-rag_model \
  -p 1234:8080 \
  -v /Users/parsa/Desk/projects/university/slmops-project/slmops-thesis/app_projects/app/pyapp/notebooks/models/rag_model/model_path/artifacts:/models \
  ghcr.io/ggerganov/llama.cpp:server \
  -m /models/model.gguf)

while ! docker logs $container_id 2>&1 | grep -q "GET /health 127.0.0.1 200"; do
  echo "Loading model and starting server..."
  docker logs --tail 10 $container_id
  sleep 1
done
echo "LlamaCpp server is ready!"

llama_model_loader: - kv  28:            tokenizer.ggml.unknown_token_id u32              = 0
llama_model_loader: - kv  29:               general.quantization_version u32              = 2
llama_model_loader: - type  f32:   61 tensors
llama_model_loader: - type q5_0:  166 tensors
llama_model_loader: - type q8_0:   15 tensors
llama_model_loader: - type q4_K:   16 tensors
llama_model_loader: - type q6_K:   14 tensors
print_info: file format = GGUF V3 (latest)
print_info: file type   = Q4_K - Medium
print_info: file size   = 98.87 MiB (6.17 BPW) 
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
  
May 8, 2025 > 17:35:30 |  pyapp.observation.instance : 97 |   ❌ ERROR  |  Error in phoenix observation: HTTPConnectionPool(host='localhost', port=6006): Max retries exceeded with url: /v1/projects/lmorbits-phoenix (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x1100d3f50>: Failed to establish a new connection: [Errno 61] Connection refused'))  
May 8, 2025 > 17:35:30 |  taskpy.main : 32 |   ❌ ERROR  |  task: [status] docker ps | grep lmorbits-obeservation | wc -l
  
May 8, 2025 > 17:35:32 |  taskpy.main : 32 |   ❌ ERROR  |  task: [start] docker pull arizephoenix/phoenix:latest
task: [start] docker run -d --name lmorbits-obeservation -p 6006:6006 -p 4317:4317 arizephoenix/phoenix:latest
  
May 8, 2025 > 17:35:43 |  taskpy.main : 32 |   ❌ ERROR  |  task: [stop] docker stop lmorbits-obeservation
task: [remove] docker rm lmorbits-obeservation
  
May 8, 2025 > 17:37:15 |  pyapp.observation.instance : 97 |   ❌ ERROR  |  Error in phoenix observation: HTTPConnectionPool(host='localhost', port=6006): Max retries exceeded with url: /v1/projects/lmorbits-phoenix (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x106923020>: Failed to establish a new connection: [Errno 61] Connection refused'))  
May 8, 2025 > 17:37:16 |  taskpy.main : 32 |   ❌ ERROR  |  task: [status] docker ps | grep lmorbits-obeservation | wc -l
  
May 8, 2025 > 17:37:17 |  taskpy.main : 32 |   ❌ ERROR  |  task: [start] docker pull arizephoenix/phoenix:latest
task: [start] docker run -d --name lmorbits-obeservation -p 6006:6006 -p 4317:4317 arizephoenix/phoenix:latest
  
May 8, 2025 > 17:37:28 |  taskpy.main : 32 |   ❌ ERROR  |  task: [stop] docker stop lmorbits-obeservation
task: [remove] docker rm lmorbits-obeservation
  
May 8, 2025 > 17:37:56 |  pyapp.observation.instance : 97 |   ❌ ERROR  |  Error in phoenix observation: HTTPConnectionPool(host='localhost', port=6006): Max retries exceeded with url: /v1/projects/lmorbits-phoenix (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x11083e090>: Failed to establish a new connection: [Errno 61] Connection refused'))  
May 8, 2025 > 17:37:56 |  taskpy.main : 32 |   ❌ ERROR  |  task: [status] docker ps | grep lmorbits-obeservation | wc -l
  
May 8, 2025 > 17:37:58 |  taskpy.main : 32 |   ❌ ERROR  |  task: [start] docker pull arizephoenix/phoenix:latest
task: [start] docker run -d --name lmorbits-obeservation -p 6006:6006 -p 4317:4317 arizephoenix/phoenix:latest
  
May 8, 2025 > 17:38:08 |  taskpy.main : 32 |   ❌ ERROR  |  task: [stop] docker stop lmorbits-obeservation
task: [remove] docker rm lmorbits-obeservation
  
May 8, 2025 > 17:39:10 |  pyapp.observation.instance : 100 |   ❌ ERROR  |  Error in phoenix observation: HTTPConnectionPool(host='localhost', port=6006): Max retries exceeded with url: /v1/projects/lmorbits-phoenix (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x1062421b0>: Failed to establish a new connection: [Errno 61] Connection refused'))  
May 8, 2025 > 17:39:10 |  taskpy.main : 32 |   ❌ ERROR  |  task: [status] docker ps | grep lmorbits-obeservation | wc -l
  
May 8, 2025 > 17:39:12 |  taskpy.main : 32 |   ❌ ERROR  |  task: [start] docker pull arizephoenix/phoenix:latest
task: [start] docker run -d --name lmorbits-obeservation -p 6006:6006 -p 4317:4317 arizephoenix/phoenix:latest
  
May 8, 2025 > 17:39:12 |  taskpy.main : 32 |   ❌ ERROR  |  task: [status] docker ps | grep lmorbits-obeservation | wc -l
  
May 8, 2025 > 17:39:43 |  pyapp.observation.instance : 100 |   ❌ ERROR  |  Error in phoenix observation: HTTPConnectionPool(host='localhost', port=6006): Max retries exceeded with url: /v1/projects/lmorbits-phoenix (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x101984cb0>: Failed to establish a new connection: [Errno 61] Connection refused'))  
May 8, 2025 > 17:39:43 |  taskpy.main : 32 |   ❌ ERROR  |  task: [status] docker ps | grep lmorbits-obeservation | wc -l
  
May 8, 2025 > 17:39:45 |  taskpy.main : 32 |   ❌ ERROR  |  task: [start] docker pull arizephoenix/phoenix:latest
task: [start] docker run -d --name lmorbits-obeservation -p 6006:6006 -p 4317:4317 arizephoenix/phoenix:latest
  
May 8, 2025 > 17:39:45 |  taskpy.main : 32 |   ❌ ERROR  |  task: [status] docker ps | grep lmorbits-obeservation | wc -l
  
May 8, 2025 > 17:40:12 |  pyapp.observation.instance : 100 |   ❌ ERROR  |  Error in phoenix observation: HTTPConnectionPool(host='localhost', port=6006): Max retries exceeded with url: /v1/projects/lmorbits-phoenix (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x107662bd0>: Failed to establish a new connection: [Errno 61] Connection refused'))  
May 8, 2025 > 17:40:12 |  taskpy.main : 32 |   ❌ ERROR  |  task: [status] docker ps | grep lmorbits-obeservation | wc -l
  
May 8, 2025 > 17:40:53 |  pyapp.observation.instance : 105 |   ❌ ERROR  |  Error in phoenix observation: HTTPConnectionPool(host='localhost', port=6006): Max retries exceeded with url: /v1/projects/lmorbits-phoenix (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x107c2ea20>: Failed to establish a new connection: [Errno 61] Connection refused'))  
May 8, 2025 > 17:40:53 |  taskpy.main : 32 |   ❌ ERROR  |  task: [status] docker ps | grep lmorbits-obeservation | wc -l
  
May 8, 2025 > 17:40:54 |  taskpy.main : 32 |   ❌ ERROR  |  task: [start] docker pull arizephoenix/phoenix:latest
task: [start] docker run -d --name lmorbits-obeservation -p 6006:6006 -p 4317:4317 arizephoenix/phoenix:latest
docker: Error response from daemon: Conflict. The container name "/lmorbits-obeservation" is already in use by container "bbad58ca5b41099e98abf05d9a667b6b93bf626c69b178843a9b825234f56263". You have to remove (or rename) that container to be able to reuse that name.
See 'docker run --help'.
task: Failed to run task "start": exit status 125
  
May 8, 2025 > 17:40:54 |  taskpy.main : 32 |   ❌ ERROR  |  task: [status] docker ps | grep lmorbits-obeservation | wc -l
  
May 8, 2025 > 17:41:31 |  pyapp.observation.instance : 106 |   ❌ ERROR  |  Error in phoenix observation: HTTPConnectionPool(host='localhost', port=6006): Max retries exceeded with url: /v1/projects/lmorbits-phoenix (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x10468e720>: Failed to establish a new connection: [Errno 61] Connection refused'))  
May 8, 2025 > 17:41:31 |  taskpy.main : 32 |   ❌ ERROR  |  task: [status] docker ps | grep lmorbits-obeservation | wc -l
  
May 8, 2025 > 17:41:33 |  taskpy.main : 32 |   ❌ ERROR  |  task: [start] docker pull arizephoenix/phoenix:latest
task: [start] docker run -d --name lmorbits-obeservation -p 6006:6006 -p 4317:4317 arizephoenix/phoenix:latest
docker: Error response from daemon: Conflict. The container name "/lmorbits-obeservation" is already in use by container "bbad58ca5b41099e98abf05d9a667b6b93bf626c69b178843a9b825234f56263". You have to remove (or rename) that container to be able to reuse that name.
See 'docker run --help'.
task: Failed to run task "start": exit status 125
  
May 8, 2025 > 17:41:33 |  taskpy.main : 32 |   ❌ ERROR  |  task: [status] docker ps | grep lmorbits-obeservation | wc -l
  
May 8, 2025 > 17:41:34 |  serve._cli.task : 33 |   ❌ ERROR  |  "docker stop" requires at least 1 argument.
See 'docker stop --help'.

Usage:  docker stop [OPTIONS] CONTAINER [CONTAINER...]

Stop one or more running containers
task: Failed to run task "delete": exit status 1
  
May 8, 2025 > 17:42:23 |  pyapp.observation.instance : 106 |   ❌ ERROR  |  Error in phoenix observation: HTTPConnectionPool(host='localhost', port=6006): Max retries exceeded with url: /v1/projects/lmorbits-phoenix (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x106a3e840>: Failed to establish a new connection: [Errno 61] Connection refused'))  
May 8, 2025 > 17:42:23 |  taskpy.main : 32 |   ❌ ERROR  |  task: [status] docker ps | grep lmorbits-obeservation | wc -l
  
May 8, 2025 > 17:42:25 |  taskpy.main : 32 |   ❌ ERROR  |  task: [start] docker pull arizephoenix/phoenix:latest
task: [start] docker run -d --name lmorbits-obeservation -p 6006:6006 -p 4317:4317 arizephoenix/phoenix:latest
docker: Error response from daemon: Conflict. The container name "/lmorbits-obeservation" is already in use by container "bbad58ca5b41099e98abf05d9a667b6b93bf626c69b178843a9b825234f56263". You have to remove (or rename) that container to be able to reuse that name.
See 'docker run --help'.
task: Failed to run task "start": exit status 125
  
May 8, 2025 > 17:42:26 |  taskpy.main : 32 |   ❌ ERROR  |  task: [status] docker ps | grep lmorbits-obeservation | wc -l
  
May 8, 2025 > 17:42:46 |  pyapp.observation.instance : 106 |   ❌ ERROR  |  Error in phoenix observation: HTTPConnectionPool(host='localhost', port=6006): Max retries exceeded with url: /v1/projects/lmorbits-phoenix (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x1046b1f10>: Failed to establish a new connection: [Errno 61] Connection refused'))  
May 8, 2025 > 17:42:46 |  taskpy.main : 32 |   ❌ ERROR  |  task: [status] docker ps | grep lmorbits-obeservation | wc -l
  
May 8, 2025 > 17:42:47 |  taskpy.main : 32 |   ❌ ERROR  |  task: [start] docker pull arizephoenix/phoenix:latest
task: [start] docker run -d --name lmorbits-obeservation -p 6006:6006 -p 4317:4317 arizephoenix/phoenix:latest
docker: Error response from daemon: Conflict. The container name "/lmorbits-obeservation" is already in use by container "bbad58ca5b41099e98abf05d9a667b6b93bf626c69b178843a9b825234f56263". You have to remove (or rename) that container to be able to reuse that name.
See 'docker run --help'.
task: Failed to run task "start": exit status 125
  
May 8, 2025 > 17:42:47 |  taskpy.main : 32 |   ❌ ERROR  |  task: [status] docker ps | grep lmorbits-obeservation | wc -l
  
May 8, 2025 > 17:42:48 |  serve._cli.task : 33 |   ❌ ERROR  |  "docker stop" requires at least 1 argument.
See 'docker stop --help'.

Usage:  docker stop [OPTIONS] CONTAINER [CONTAINER...]

Stop one or more running containers
task: Failed to run task "delete": exit status 1
  
May 8, 2025 > 17:44:29 |  serve.servers.llamacpp.serve : 164 |   ❌ ERROR  |  Failed to get status for model rag_model: Model ID 'rag_model' not found  
May 8, 2025 > 17:45:00 |  serve._cli.task : 33 |   ❌ ERROR  |  task: [serve] echo "Starting LlamaCpp server and waiting for it to be ready..."
task: [serve] container_id=$(docker run -d \
  --name lmorbits-llamacpp-rag_model \
  -p 1234:8080 \
  -v /Users/parsa/Desk/projects/university/slmops-project/slmops-thesis/app_projects/app/pyapp/notebooks/models/rag_model/model_path/artifacts:/models \
  ghcr.io/ggerganov/llama.cpp:server \
  -m /models/model.gguf)

while ! docker logs $container_id 2>&1 | grep -q "GET /health 127.0.0.1 200"; do
  echo "Loading model and starting server..."
  docker logs --tail 10 $container_id
  sleep 1
done
echo "LlamaCpp server is ready!"

llama_model_loader: - kv  28:            tokenizer.ggml.unknown_token_id u32              = 0
llama_model_loader: - kv  29:               general.quantization_version u32              = 2
llama_model_loader: - type  f32:   61 tensors
llama_model_loader: - type q5_0:  166 tensors
llama_model_loader: - type q8_0:   15 tensors
llama_model_loader: - type q4_K:   16 tensors
llama_model_loader: - type q6_K:   14 tensors
print_info: file format = GGUF V3 (latest)
print_info: file type   = Q4_K - Medium
print_info: file size   = 98.87 MiB (6.17 BPW) 
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
  
May 8, 2025 > 17:45:45 |  pyapp.observation.instance : 106 |   ❌ ERROR  |  Error in phoenix observation: HTTPConnectionPool(host='localhost', port=6006): Max retries exceeded with url: /v1/projects/lmorbits-phoenix (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x10384a060>: Failed to establish a new connection: [Errno 61] Connection refused'))  
May 8, 2025 > 17:45:45 |  taskpy.main : 32 |   ❌ ERROR  |  task: [status] docker ps | grep lmorbits-obeservation | wc -l
  
May 8, 2025 > 17:45:47 |  taskpy.main : 32 |   ❌ ERROR  |  task: [start] docker pull arizephoenix/phoenix:latest
task: [start] docker run -d --name lmorbits-obeservation -p 6006:6006 -p 4317:4317 arizephoenix/phoenix:latest
docker: Error response from daemon: Conflict. The container name "/lmorbits-obeservation" is already in use by container "bbad58ca5b41099e98abf05d9a667b6b93bf626c69b178843a9b825234f56263". You have to remove (or rename) that container to be able to reuse that name.
See 'docker run --help'.
task: Failed to run task "start": exit status 125
  
May 8, 2025 > 17:45:47 |  taskpy.main : 32 |   ❌ ERROR  |  task: [status] docker ps | grep lmorbits-obeservation | wc -l
  
May 8, 2025 > 17:49:06 |  pyapp.observation.instance : 99 |   ❌ ERROR  |  Error in phoenix observation: HTTPConnectionPool(host='localhost', port=6006): Max retries exceeded with url: /v1/projects/lmorbits-phoenix (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x103523980>: Failed to establish a new connection: [Errno 61] Connection refused'))  
May 8, 2025 > 17:49:06 |  taskpy.main : 32 |   ❌ ERROR  |  task: [status] docker ps | grep lmorbits-obeservation | wc -l
  
May 8, 2025 > 17:49:08 |  taskpy.main : 32 |   ❌ ERROR  |  task: [start] docker pull arizephoenix/phoenix:latest
task: [start] docker run -d --name lmorbits-obeservation -p 6006:6006 -p 4317:4317 arizephoenix/phoenix:latest
docker: Error response from daemon: Conflict. The container name "/lmorbits-obeservation" is already in use by container "bbad58ca5b41099e98abf05d9a667b6b93bf626c69b178843a9b825234f56263". You have to remove (or rename) that container to be able to reuse that name.
See 'docker run --help'.
task: Failed to run task "start": exit status 125
  
May 8, 2025 > 17:49:08 |  taskpy.main : 32 |   ❌ ERROR  |  task: [remove] if [ "$(docker ps -q -f name=lmorbits-obeservation)" ]; then
    docker stop $(docker ps -q -f name=lmorbits-obeservation)
fi
docker rm $(docker ps -aq -f name=lmorbits-obeservation)

  
May 8, 2025 > 17:49:09 |  serve._cli.task : 33 |   ❌ ERROR  |  "docker rm" requires at least 1 argument.
See 'docker rm --help'.

Usage:  docker rm [OPTIONS] CONTAINER [CONTAINER...]

Remove one or more containers
task: Failed to run task "delete": exit status 1
  
May 8, 2025 > 17:50:29 |  pyapp.observation.instance : 99 |   ❌ ERROR  |  Error in phoenix observation: HTTPConnectionPool(host='localhost', port=6006): Max retries exceeded with url: /v1/projects/lmorbits-phoenix (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x109d3e090>: Failed to establish a new connection: [Errno 61] Connection refused'))  
May 8, 2025 > 17:50:29 |  taskpy.main : 32 |   ❌ ERROR  |  task: [status] docker ps | grep lmorbits-obeservation | wc -l
  
May 8, 2025 > 17:50:31 |  taskpy.main : 32 |   ❌ ERROR  |  task: [start] docker pull arizephoenix/phoenix:latest
task: [start] docker run -d --name lmorbits-obeservation -p 6006:6006 -p 4317:4317 arizephoenix/phoenix:latest
  
May 8, 2025 > 17:50:41 |  taskpy.main : 32 |   ❌ ERROR  |  task: [remove] if [ "$(docker ps -q -f name=lmorbits-obeservation)" ]; then
    docker stop $(docker ps -q -f name=lmorbits-obeservation)
    docker rm $(docker ps -aq -f name=lmorbits-obeservation)
fi

  
May 8, 2025 > 17:50:42 |  serve._cli.task : 33 |   ❌ ERROR  |  "docker rm" requires at least 1 argument.
See 'docker rm --help'.

Usage:  docker rm [OPTIONS] CONTAINER [CONTAINER...]

Remove one or more containers
task: Failed to run task "delete": exit status 1
  
May 8, 2025 > 17:51:37 |  taskpy.main : 32 |   ❌ ERROR  |  task: [remove] if [ "$(docker ps -q -f name=lmorbits-obeservation)" ]; then
    docker stop $(docker ps -q -f name=lmorbits-obeservation)
    docker rm $(docker ps -aq -f name=lmorbits-obeservation)
fi

  
May 8, 2025 > 17:51:38 |  serve._cli.task : 33 |   ❌ ERROR  |  "docker rm" requires at least 1 argument.
See 'docker rm --help'.

Usage:  docker rm [OPTIONS] CONTAINER [CONTAINER...]

Remove one or more containers
task: Failed to run task "delete": exit status 1
  
May 8, 2025 > 17:52:41 |  taskpy.main : 32 |   ❌ ERROR  |  task: [remove] if [ "$(docker ps -q -f name=lmorbits-obeservation | wc -l)" -gt 0 ]; then
    docker stop $(docker ps -q -f name=lmorbits-obeservation)
    docker rm $(docker ps -aq -f name=lmorbits-obeservation)
fi

  
May 8, 2025 > 17:52:42 |  serve._cli.task : 33 |   ❌ ERROR  |  "docker rm" requires at least 1 argument.
See 'docker rm --help'.

Usage:  docker rm [OPTIONS] CONTAINER [CONTAINER...]

Remove one or more containers
task: Failed to run task "delete": exit status 1
  
May 8, 2025 > 17:53:00 |  taskpy.main : 32 |   ❌ ERROR  |  task: [remove] if [ "$(docker ps -q -f name=lmorbits-obeservation | wc -l)" -gt 0 ]; then
    docker stop $(docker ps -q -f name=lmorbits-obeservation)
    docker rm $(docker ps -aq -f name=lmorbits-obeservation)

task: Failed to run task "remove": 1:1: if statement must end with "fi"
  
May 8, 2025 > 17:53:00 |  serve._cli.task : 33 |   ❌ ERROR  |  "docker rm" requires at least 1 argument.
See 'docker rm --help'.

Usage:  docker rm [OPTIONS] CONTAINER [CONTAINER...]

Remove one or more containers
task: Failed to run task "delete": exit status 1
  
May 8, 2025 > 17:58:47 |  taskpy.main : 32 |   ❌ ERROR  |  task: [remove] if [ "$(docker ps -q -f name=lmorbits-obeservation | wc -l)" -gt 0 ]; then
    docker stop $(docker ps -q -f name=lmorbits-obeservation)
    docker rm $(docker ps -aq -f name=lmorbits-obeservation)
fi

  
May 8, 2025 > 17:58:48 |  serve._cli.task : 33 |   ❌ ERROR  |  "docker rm" requires at least 1 argument.
See 'docker rm --help'.

Usage:  docker rm [OPTIONS] CONTAINER [CONTAINER...]

Remove one or more containers
task: Failed to run task "delete": exit status 1
  
May 8, 2025 > 18:00:37 |  taskpy.main : 32 |   ❌ ERROR  |  task: [remove] if [ "$(docker ps -q -f name=lmorbits-obeservation | wc -l)" -gt 0 ]; then
    docker stop $(docker ps -q -f name=lmorbits-obeservation)
    docker rm $(docker ps -aq -f name=lmorbits-obeservation)
fi

  
May 8, 2025 > 18:00:38 |  serve._cli.task : 33 |   ❌ ERROR  |  "docker rm" requires at least 1 argument.
See 'docker rm --help'.

Usage:  docker rm [OPTIONS] CONTAINER [CONTAINER...]

Remove one or more containers
task: Failed to run task "delete": exit status 1
  
May 8, 2025 > 18:10:05 |  taskpy.main : 32 |   ❌ ERROR  |  task: [remove] if [ "$(docker ps -q -f name=lmorbits-obeservation | wc -l)" -gt 0 ]; then
    docker stop $(docker ps -q -f name=lmorbits-obeservation)
    docker rm $(docker ps -aq -f name=lmorbits-obeservation)
fi

  
May 8, 2025 > 18:10:06 |  serve._cli.task : 33 |   ❌ ERROR  |  "docker rm" requires at least 1 argument.
See 'docker rm --help'.

Usage:  docker rm [OPTIONS] CONTAINER [CONTAINER...]

Remove one or more containers
task: Failed to run task "delete": exit status 1
  
May 8, 2025 > 18:10:52 |  taskpy.main : 32 |   ❌ ERROR  |  task: [remove] if [ "$(docker ps -q -f name=lmorbits-obeservation | wc -l)" -gt 0 ]; then
    docker stop $(docker ps -q -f name=lmorbits-obeservation)
    docker rm $(docker ps -aq -f name=lmorbits-obeservation)
fi

  
May 8, 2025 > 18:11:20 |  taskpy.main : 32 |   ❌ ERROR  |  task: [remove] if [ "$(docker ps -q -f name=lmorbits-obeservation)" ]; then
     docker stop $(docker ps -q -f name=lmorbits-obeservation)
     docker rm $(docker ps -aq -f name=lmorbits-obeservation)
   fi

  
May 8, 2025 > 18:12:00 |  taskpy.main : 32 |   ❌ ERROR  |  task: Failed to parse ../src/pyapp/observation/Taskfile.yml:
yaml: line 21: did not find expected '-' indicator
  
May 8, 2025 > 18:12:21 |  taskpy.main : 32 |   ❌ ERROR  |  task: [remove] if ; then
  if [ "$(docker ps -q -f name=lmorbits-obeservation)" ]; then
    docker stop $(docker ps -q -f name=lmorbits-obeservation)
    docker rm $(docker ps -aq -f name=lmorbits-obeservation)
  fi
  
else
   if [ "$(docker ps -q -f name=lmorbits-obeservation)" ]; then
    docker stop $(docker ps -q -f name=lmorbits-obeservation)
    docker rm $(docker ps -aq -f name=lmorbits-obeservation)
  fi
fi
if ; then
  docker image rm arizephoenix/phoenix:latest
fi

  
May 8, 2025 > 18:13:17 |  serve.servers.llamacpp.serve : 164 |   ❌ ERROR  |  Failed to get status for model rag_model: Model ID 'rag_model' not found  
May 8, 2025 > 18:13:48 |  serve._cli.task : 33 |   ❌ ERROR  |  task: [serve] echo "Starting LlamaCpp server and waiting for it to be ready..."
task: [serve] container_id=$(docker run -d \
  --name lmorbits-llamacpp-rag_model \
  -p 1234:8080 \
  -v /Users/parsa/Desk/projects/university/slmops-project/slmops-thesis/app_projects/app/pyapp/notebooks/models/rag_model/model_path/artifacts:/models \
  ghcr.io/ggerganov/llama.cpp:server \
  -m /models/model.gguf)

while ! docker logs $container_id 2>&1 | grep -q "GET /health 127.0.0.1 200"; do
  echo "Loading model and starting server..."
  docker logs --tail 10 $container_id
  sleep 1
done
echo "LlamaCpp server is ready!"

llama_model_loader: - kv  28:            tokenizer.ggml.unknown_token_id u32              = 0
llama_model_loader: - kv  29:               general.quantization_version u32              = 2
llama_model_loader: - type  f32:   61 tensors
llama_model_loader: - type q5_0:  166 tensors
llama_model_loader: - type q8_0:   15 tensors
llama_model_loader: - type q4_K:   16 tensors
llama_model_loader: - type q6_K:   14 tensors
print_info: file format = GGUF V3 (latest)
print_info: file type   = Q4_K - Medium
print_info: file size   = 98.87 MiB (6.17 BPW) 
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
  
May 8, 2025 > 18:13:49 |  pyapp.observation.instance : 99 |   ❌ ERROR  |  Error in phoenix observation: HTTPConnectionPool(host='localhost', port=6006): Max retries exceeded with url: /v1/projects/lmorbits-phoenix (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x12b99b4a0>: Failed to establish a new connection: [Errno 61] Connection refused'))  
May 8, 2025 > 18:13:50 |  taskpy.main : 32 |   ❌ ERROR  |  task: [status] docker ps | grep lmorbits-obeservation | wc -l
  
May 8, 2025 > 18:14:10 |  taskpy.main : 32 |   ❌ ERROR  |  task: [start] docker pull arizephoenix/phoenix:latest
task: [start] docker run -d --name lmorbits-obeservation -p 6006:6006 -p 4317:4317 arizephoenix/phoenix:latest
  
May 8, 2025 > 18:14:13 |  taskpy.main : 32 |   ❌ ERROR  |  task: [status] docker ps | grep lmorbits-obeservation | wc -l
  
May 8, 2025 > 18:23:27 |  taskpy.main : 32 |   ❌ ERROR  |  task: [remove] if [ "$(docker ps -q -f name=lmorbits-obeservation)" ]; then
     docker stop $(docker ps -q -f name=lmorbits-obeservation)
     docker rm $(docker ps -aq -f name=lmorbits-obeservation)
   fi

  
May 8, 2025 > 18:28:55 |  serve.servers.llamacpp.serve : 164 |   ❌ ERROR  |  Failed to get status for model rag_model: Model ID 'rag_model' not found  
May 8, 2025 > 18:29:26 |  serve._cli.task : 33 |   ❌ ERROR  |  task: [serve] echo "Starting LlamaCpp server and waiting for it to be ready..."
task: [serve] container_id=$(docker run -d \
  --name lmorbits-llamacpp-rag_model \
  -p 1234:8080 \
  -v /Users/parsa/Desk/projects/university/slmops-project/slmops-thesis/app_projects/app/pyapp/notebooks/models/rag_model/model_path/artifacts:/models \
  ghcr.io/ggerganov/llama.cpp:server \
  -m /models/model.gguf)

while ! docker logs $container_id 2>&1 | grep -q "GET /health 127.0.0.1 200"; do
  echo "Loading model and starting server..."
  docker logs --tail 10 $container_id
  sleep 1
done
echo "LlamaCpp server is ready!"

llama_model_loader: - kv  28:            tokenizer.ggml.unknown_token_id u32              = 0
llama_model_loader: - kv  29:               general.quantization_version u32              = 2
llama_model_loader: - type  f32:   61 tensors
llama_model_loader: - type q5_0:  166 tensors
llama_model_loader: - type q8_0:   15 tensors
llama_model_loader: - type q4_K:   16 tensors
llama_model_loader: - type q6_K:   14 tensors
print_info: file format = GGUF V3 (latest)
print_info: file type   = Q4_K - Medium
print_info: file size   = 98.87 MiB (6.17 BPW) 
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
  
May 8, 2025 > 18:29:29 |  pyapp.observation.instance : 99 |   ❌ ERROR  |  Error in phoenix observation: HTTPConnectionPool(host='localhost', port=6006): Max retries exceeded with url: /v1/projects/lmorbits-phoenix (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x13c5b2ed0>: Failed to establish a new connection: [Errno 61] Connection refused'))  
May 8, 2025 > 18:30:42 |  taskpy.main : 34 |   ❌ ERROR  |  task: [stop] if [ "$(docker ps -q -f name=lmorbits-obeservation | wc -l)" -gt 0 ]; then docker stop $(docker ps -q -f name=lmorbits-obeservation) fi
task: Failed to run task "stop": 1:1: if statement must end with "fi"
  
May 8, 2025 > 18:33:19 |  serve.servers.llamacpp.serve : 164 |   ❌ ERROR  |  Failed to get status for model rag_model: Model ID 'rag_model' not found  
May 8, 2025 > 18:33:19 |  serve._cli.task : 33 |   ❌ ERROR  |  [32mtask: [serve] echo "Starting LlamaCpp server and waiting for it to be ready..."
[0m[32mtask: [serve] container_id=$(docker run -d \
  --name lmorbits-llamacpp-rag_model \
  -p 8080:8080 \
  -v /Users/parsa/Desk/projects/university/slmops-project/slmops-thesis/app_projects/app/pyapp/notebooks/models/rag_model/model_path/artifacts:/models \
  ghcr.io/ggerganov/llama.cpp:server \
  -m /models/model.gguf)

while ! docker logs $container_id 2>&1 | grep -q "GET /health 127.0.0.1 200"; do
  echo "Loading model and starting server..."
  docker logs --tail 10 $container_id
  sleep 1
done
echo "LlamaCpp server is ready!"

[0mdocker: Error response from daemon: Conflict. The container name "/lmorbits-llamacpp-rag_model" is already in use by container "1cc66a644e8327b823c558d5bf8e35a10640b08e21e57a62bf93ffbf2641c201". You have to remove (or rename) that container to be able to reuse that name.
See 'docker run --help'.
[31mtask: Failed to run task "serve": exit status 125
[0m  
May 8, 2025 > 18:46:49 |  serve._cli.task : 33 |   ❌ ERROR  |  task: Failed to run task "status": exit status 1
  
May 8, 2025 > 18:46:49 |  pyapp.observation.instance : 99 |   ❌ ERROR  |  Error in phoenix observation: HTTPConnectionPool(host='localhost', port=6006): Max retries exceeded with url: /v1/projects/lmorbits-phoenix (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x140c148c0>: Failed to establish a new connection: [Errno 61] Connection refused'))  
May 8, 2025 > 18:46:51 |  taskpy.main : 34 |   ❌ ERROR  |  task: [start] docker pull arizephoenix/phoenix:latest
task: [start] docker run -d --name lmorbits-obeservation -p 6006:6006 -p 4317:4317 arizephoenix/phoenix:latest
docker: Error response from daemon: Conflict. The container name "/lmorbits-obeservation" is already in use by container "f42882f88711091cba188c77df2a4d6d10d68bb4aeaa4bdd7438f86e95b8e63d". You have to remove (or rename) that container to be able to reuse that name.
See 'docker run --help'.
task: Failed to run task "start": exit status 125
  
May 8, 2025 > 18:46:53 |  taskpy.main : 34 |   ❌ ERROR  |  task: [start] docker pull arizephoenix/phoenix:latest
task: [start] docker run -d --name lmorbits-obeservation -p 6006:6006 -p 4317:4317 arizephoenix/phoenix:latest
docker: Error response from daemon: Conflict. The container name "/lmorbits-obeservation" is already in use by container "f42882f88711091cba188c77df2a4d6d10d68bb4aeaa4bdd7438f86e95b8e63d". You have to remove (or rename) that container to be able to reuse that name.
See 'docker run --help'.
task: Failed to run task "start": exit status 125
  
May 8, 2025 > 18:56:39 |  serve._cli.task : 33 |   ❌ ERROR  |  task: Failed to run task "status": exit status 1
  
May 8, 2025 > 18:56:40 |  pyapp.observation.instance : 99 |   ❌ ERROR  |  Error in phoenix observation: HTTPConnectionPool(host='localhost', port=6006): Max retries exceeded with url: /v1/projects/lmorbits-phoenix (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x137714fb0>: Failed to establish a new connection: [Errno 61] Connection refused'))  
May 8, 2025 > 18:56:40 |  taskpy.main : 34 |   ❌ ERROR  |  task: [start] if [ "$(docker ps -q  --filter "status=exited" -f name=lmorbits-obeservation)" ]; then
  docker start lmorbits-obeservation
else
  container_id=$(docker run -d \
    --name lmorbits-obeservation \
    -p 6006:6006 \
    -p 4317:4317 \
    arizephoenix/phoenix:latest)\
fi

task: Failed to run task "start": 1:1: if statement must end with "fi"
  
May 8, 2025 > 18:56:40 |  taskpy.main : 34 |   ❌ ERROR  |  task: [start] if [ "$(docker ps -q  --filter "status=exited" -f name=lmorbits-obeservation)" ]; then
  docker start lmorbits-obeservation
else
  container_id=$(docker run -d \
    --name lmorbits-obeservation \
    -p 6006:6006 \
    -p 4317:4317 \
    arizephoenix/phoenix:latest)\
fi

task: Failed to run task "start": 1:1: if statement must end with "fi"
  
May 8, 2025 > 18:57:22 |  serve._cli.task : 33 |   ❌ ERROR  |  task: Failed to run task "status": exit status 1
  
May 8, 2025 > 18:57:23 |  pyapp.observation.instance : 99 |   ❌ ERROR  |  Error in phoenix observation: HTTPConnectionPool(host='localhost', port=6006): Max retries exceeded with url: /v1/projects/lmorbits-phoenix (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x140bb13a0>: Failed to establish a new connection: [Errno 61] Connection refused'))  
May 8, 2025 > 18:57:23 |  taskpy.main : 34 |   ❌ ERROR  |  task: [start] if [ "$(docker ps -q  --filter "status=exited" -f name=lmorbits-obeservation)" ]; then
  docker start lmorbits-obeservation
else
  container_id=$(docker run -d \
    --name lmorbits-obeservation \
    -p 6006:6006 \
    -p 4317:4317 \
    arizephoenix/phoenix:latest)\
fi

task: Failed to run task "start": 1:1: if statement must end with "fi"
  
May 8, 2025 > 18:57:23 |  taskpy.main : 34 |   ❌ ERROR  |  task: [start] if [ "$(docker ps -q  --filter "status=exited" -f name=lmorbits-obeservation)" ]; then
  docker start lmorbits-obeservation
else
  container_id=$(docker run -d \
    --name lmorbits-obeservation \
    -p 6006:6006 \
    -p 4317:4317 \
    arizephoenix/phoenix:latest)\
fi

task: Failed to run task "start": 1:1: if statement must end with "fi"
  
May 8, 2025 > 18:57:57 |  serve._cli.task : 33 |   ❌ ERROR  |  task: Failed to run task "status": exit status 1
  
May 8, 2025 > 18:57:57 |  pyapp.observation.instance : 99 |   ❌ ERROR  |  Error in phoenix observation: HTTPConnectionPool(host='localhost', port=6006): Max retries exceeded with url: /v1/projects/lmorbits-phoenix (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x125675250>: Failed to establish a new connection: [Errno 61] Connection refused'))  
May 8, 2025 > 18:57:58 |  taskpy.main : 34 |   ❌ ERROR  |  task: [start] if [ "$(docker ps -q  --filter "status=exited" -f name=lmorbits-obeservation)" ]; then
  docker start lmorbits-obeservation
else
  container_id=$(docker run -d \
    --name lmorbits-obeservation \
    -p 6006:6006 \
    -p 4317:4317 \
    arizephoenix/phoenix:latest)\
fi

task: Failed to run task "start": 1:1: if statement must end with "fi"
  
May 8, 2025 > 18:57:58 |  taskpy.main : 34 |   ❌ ERROR  |  task: [start] if [ "$(docker ps -q  --filter "status=exited" -f name=lmorbits-obeservation)" ]; then
  docker start lmorbits-obeservation
else
  container_id=$(docker run -d \
    --name lmorbits-obeservation \
    -p 6006:6006 \
    -p 4317:4317 \
    arizephoenix/phoenix:latest)\
fi

task: Failed to run task "start": 1:1: if statement must end with "fi"
  
May 8, 2025 > 18:59:07 |  serve._cli.task : 33 |   ❌ ERROR  |  task: Failed to run task "status": exit status 1
  
May 8, 2025 > 18:59:07 |  pyapp.observation.instance : 99 |   ❌ ERROR  |  Error in phoenix observation: HTTPConnectionPool(host='localhost', port=6006): Max retries exceeded with url: /v1/projects/lmorbits-phoenix (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x119b6f950>: Failed to establish a new connection: [Errno 61] Connection refused'))  
May 8, 2025 > 19:00:20 |  serve._cli.task : 33 |   ❌ ERROR  |  task: Failed to run task "status": exit status 1
  
May 8, 2025 > 19:00:21 |  pyapp.observation.instance : 99 |   ❌ ERROR  |  Error in phoenix observation: Expecting value: line 1 column 1 (char 0)  
May 8, 2025 > 19:02:14 |  serve._cli.task : 33 |   ❌ ERROR  |  task: Failed to run task "status": exit status 1
  
May 8, 2025 > 19:02:15 |  pyapp.observation.instance : 99 |   ❌ ERROR  |  Error in phoenix observation: Expecting value: line 1 column 1 (char 0)  
May 8, 2025 > 19:08:01 |  serve._cli.task : 33 |   ❌ ERROR  |  task: Failed to run task "status": exit status 1
  
May 8, 2025 > 19:10:48 |  serve._cli.task : 33 |   ❌ ERROR  |  task: [serve] echo "Starting LlamaCpp server and waiting for it to be ready..."
task: [serve] if [ "$(docker ps -q --filter "status=exited" -f name=lmorbits-llamacpp-rag_model)" ]; then
  docker start lmorbits-llamacpp-rag_model
  container_id=$(docker ps -aqf "name=lmorbits-llamacpp-rag_model")
else
  container_id=$(docker run -d \
    --name lmorbits-llamacpp-rag_model \
    -p 1234:8080 \
    -v /Users/parsa/Desk/projects/university/slmops-project/slmops-thesis/app_projects/app/pyapp/notebooks/models/rag_model/model_path/artifacts:/models \
    ghcr.io/ggerganov/llama.cpp:server \
    -m /models/model.gguf)
fi

echo "🕐 Waiting for LlamaCpp server to become healthy..."
while ! docker logs $container_id 2>&1 | grep -q "GET /health 127.0.0.1 200"; do
  echo "⏳ Still starting..."
  docker logs --tail 10 $container_id
  sleep 1
done

echo "✅ LlamaCpp server is ready!"

  
May 8, 2025 > 19:11:39 |  serve._cli.task : 33 |   ❌ ERROR  |  task: [serve] echo "Starting LlamaCpp server and waiting for it to be ready..."
task: [serve] if [ "$(docker ps -q --filter "status=exited" -f name=lmorbits-llamacpp-rag_model)" ]; then
  docker start lmorbits-llamacpp-rag_model
  container_id=$(docker ps -aqf "name=lmorbits-llamacpp-rag_model")
else
  container_id=$(docker run -d \
    --name lmorbits-llamacpp-rag_model \
    -p 1234:8080 \
    -v /Users/parsa/Desk/projects/university/slmops-project/slmops-thesis/app_projects/app/pyapp/notebooks/models/rag_model/model_path/artifacts:/models \
    ghcr.io/ggerganov/llama.cpp:server \
    -m /models/model.gguf)
fi

echo "🕐 Waiting for LlamaCpp server to become healthy..."
while ! docker logs $container_id 2>&1 | grep -q "GET /health 127.0.0.1 200"; do
  echo "⏳ Still starting..."
  docker logs --tail 10 $container_id
  sleep 1
done

echo "✅ LlamaCpp server is ready!"

  
May 8, 2025 > 19:11:56 |  pyapp.observation.instance : 99 |   ❌ ERROR  |  Error in phoenix observation: HTTPConnectionPool(host='localhost', port=6006): Max retries exceeded with url: /v1/projects/lmorbits-phoenix (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x150da7fe0>: Failed to establish a new connection: [Errno 61] Connection refused'))  
May 8, 2025 > 19:12:49 |  serve._cli.task : 33 |   ❌ ERROR  |  task: [serve] echo "Starting LlamaCpp server and waiting for it to be ready..."
task: [serve] if [ "$(docker ps -q --filter "status=exited" -f name=lmorbits-llamacpp-rag_model)" ]; then
  docker start lmorbits-llamacpp-rag_model
  container_id=$(docker ps -aqf "name=lmorbits-llamacpp-rag_model")
else
  container_id=$(docker run -d \
    --name lmorbits-llamacpp-rag_model \
    -p 1234:8080 \
    -v /Users/parsa/Desk/projects/university/slmops-project/slmops-thesis/app_projects/app/pyapp/notebooks/models/rag_model/model_path/artifacts:/models \
    ghcr.io/ggerganov/llama.cpp:server \
    -m /models/model.gguf)
fi

echo "🕐 Waiting for LlamaCpp server to become healthy..."
while ! docker logs $container_id 2>&1 | grep -q "GET /health 127.0.0.1 200"; do
  echo "⏳ Still starting..."
  docker logs --tail 10 $container_id
  sleep 1
done

echo "✅ LlamaCpp server is ready!"

llama_model_loader: - kv  28:            tokenizer.ggml.unknown_token_id u32              = 0
llama_model_loader: - kv  29:               general.quantization_version u32              = 2
llama_model_loader: - type  f32:   61 tensors
llama_model_loader: - type q5_0:  166 tensors
llama_model_loader: - type q8_0:   15 tensors
llama_model_loader: - type q4_K:   16 tensors
llama_model_loader: - type q6_K:   14 tensors
print_info: file format = GGUF V3 (latest)
print_info: file type   = Q4_K - Medium
print_info: file size   = 98.87 MiB (6.17 BPW) 
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
  
May 8, 2025 > 19:12:49 |  pyapp.observation.instance : 99 |   ❌ ERROR  |  Error in phoenix observation: HTTPConnectionPool(host='localhost', port=6006): Max retries exceeded with url: /v1/projects/lmorbits-phoenix (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x140b16510>: Failed to establish a new connection: [Errno 61] Connection refused'))  
May 8, 2025 > 19:15:29 |  serve._cli.task : 33 |   ❌ ERROR  |  task: [serve] echo "Starting LlamaCpp server and waiting for it to be ready..."
task: [serve] if [ "$(docker ps -q --filter "status=exited" -f name=lmorbits-llamacpp-rag_model)" ]; then
  docker start lmorbits-llamacpp-rag_model
  container_id=$(docker ps -aqf "name=lmorbits-llamacpp-rag_model")
else
  container_id=$(docker run -d \
    --name lmorbits-llamacpp-rag_model \
    -p 1234:8080 \
    -v /Users/parsa/Desk/projects/university/slmops-project/slmops-thesis/app_projects/app/pyapp/notebooks/models/rag_model/model_path/artifacts:/models \
    ghcr.io/ggerganov/llama.cpp:server \
    -m /models/model.gguf)
fi

echo "🕐 Waiting for LlamaCpp server to become healthy..."
while ! docker logs $container_id 2>&1 | grep -q "GET /health 127.0.0.1 200"; do
  echo "⏳ Still starting..."
  docker logs --tail 10 $container_id
  sleep 1
done

echo "✅ LlamaCpp server is ready!"

llama_model_loader: - kv  28:            tokenizer.ggml.unknown_token_id u32              = 0
llama_model_loader: - kv  29:               general.quantization_version u32              = 2
llama_model_loader: - type  f32:   61 tensors
llama_model_loader: - type q5_0:  166 tensors
llama_model_loader: - type q8_0:   15 tensors
llama_model_loader: - type q4_K:   16 tensors
llama_model_loader: - type q6_K:   14 tensors
print_info: file format = GGUF V3 (latest)
print_info: file type   = Q4_K - Medium
print_info: file size   = 98.87 MiB (6.17 BPW) 
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
  
May 8, 2025 > 19:15:30 |  pyapp.observation.instance : 99 |   ❌ ERROR  |  Error in phoenix observation: HTTPConnectionPool(host='localhost', port=6006): Max retries exceeded with url: /v1/projects/lmorbits-phoenix (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x171ec7920>: Failed to establish a new connection: [Errno 61] Connection refused'))  
May 10, 2025 > 20:50:31 |  serve._cli.task : 33 |   ❌ ERROR  |  "docker rm" requires at least 1 argument.
See 'docker rm --help'.

Usage:  docker rm [OPTIONS] CONTAINER [CONTAINER...]

Remove one or more containers
task: Failed to run task "delete": exit status 1
  
May 10, 2025 > 20:51:06 |  serve._cli.task : 33 |   ❌ ERROR  |  "docker rm" requires at least 1 argument.
See 'docker rm --help'.

Usage:  docker rm [OPTIONS] CONTAINER [CONTAINER...]

Remove one or more containers
task: Failed to run task "delete": exit status 1
  
May 10, 2025 > 20:51:07 |  serve._cli.task : 33 |   ❌ ERROR  |  task: [serve] echo "Starting LlamaCpp server and waiting for it to be ready..."
task: [serve] if [ "$(docker ps -q --filter "status=exited" -f name=lmorbits-llamacpp-rag_model)" ]; then
  docker start lmorbits-llamacpp-rag_model
  container_id=$(docker ps -aqf "name=lmorbits-llamacpp-rag_model")
else
  container_id=$(docker run -d \
    --name lmorbits-llamacpp-rag_model \
    -p 8080:8080 \
    -v models/rag_model/model_path/artifacts:/models \
    ghcr.io/ggerganov/llama.cpp:server \
    -m /models/model.gguf)
fi

echo "🕐 Waiting for LlamaCpp server to become healthy..."
while ! docker logs $container_id 2>&1 | grep -q "GET /health 127.0.0.1 200"; do
  echo "⏳ Still starting..."
  docker logs --tail 10 $container_id
  sleep 1
done

echo "✅ LlamaCpp server is ready!"

docker: Error response from daemon: create models/rag_model/model_path/artifacts: "models/rag_model/model_path/artifacts" includes invalid characters for a local volume name, only "[a-zA-Z0-9][a-zA-Z0-9_.-]" are allowed. If you intended to pass a host directory, use absolute path.
See 'docker run --help'.
task: Failed to run task "serve": exit status 125
  
May 10, 2025 > 20:55:49 |  serve._cli.task : 33 |   ❌ ERROR  |  task: [serve] echo "Starting LlamaCpp server and waiting for it to be ready..."
task: [serve] if [ "$(docker ps -q --filter "status=exited" -f name=lmorbits-llamacpp-rag_model)" ]; then
  docker start lmorbits-llamacpp-rag_model
  container_id=$(docker ps -aqf "name=lmorbits-llamacpp-rag_model")
else
  container_id=$(docker run -d \
    --name lmorbits-llamacpp-rag_model \
    -p 8080:8080 \
    -v models/models/rag_model/model_path/artifacts:/models \
    ghcr.io/ggerganov/llama.cpp:server \
    -m /models/model.gguf)
fi

echo "🕐 Waiting for LlamaCpp server to become healthy..."
while ! docker logs $container_id 2>&1 | grep -q "GET /health 127.0.0.1 200"; do
  echo "⏳ Still starting..."
  docker logs --tail 10 $container_id
  sleep 1
done

echo "✅ LlamaCpp server is ready!"

docker: Error response from daemon: create models/models/rag_model/model_path/artifacts: "models/models/rag_model/model_path/artifacts" includes invalid characters for a local volume name, only "[a-zA-Z0-9][a-zA-Z0-9_.-]" are allowed. If you intended to pass a host directory, use absolute path.
See 'docker run --help'.
task: Failed to run task "serve": exit status 125
  
May 10, 2025 > 21:03:53 |  serve._cli.task : 33 |   ❌ ERROR  |  "docker rm" requires at least 1 argument.
See 'docker rm --help'.

Usage:  docker rm [OPTIONS] CONTAINER [CONTAINER...]

Remove one or more containers
task: Failed to run task "delete": exit status 1
  
May 10, 2025 > 21:04:25 |  serve._cli.task : 33 |   ❌ ERROR  |  task: [serve] echo "Starting LlamaCpp server and waiting for it to be ready..."
task: [serve] if [ "$(docker ps -q --filter "status=exited" -f name=lmorbits-llamacpp-rag_model)" ]; then
  docker start lmorbits-llamacpp-rag_model
  container_id=$(docker ps -aqf "name=lmorbits-llamacpp-rag_model")
else
  container_id=$(docker run -d \
    --name lmorbits-llamacpp-rag_model \
    -p 8080:8080 \
    -v /Users/parsa/Desk/projects/university/slmops-project/slmops-thesis/app_projects/app/pyapp/notebooks/models/rag_model/model_path/artifacts:/models \
    ghcr.io/ggerganov/llama.cpp:server \
    -m /models/model.gguf)
fi

echo "🕐 Waiting for LlamaCpp server to become healthy..."
while ! docker logs $container_id 2>&1 | grep -q "GET /health 127.0.0.1 200"; do
  echo "⏳ Still starting..."
  docker logs --tail 10 $container_id
  sleep 1
done

echo "✅ LlamaCpp server is ready!"

llama_model_loader: - kv  28:            tokenizer.ggml.unknown_token_id u32              = 0
llama_model_loader: - kv  29:               general.quantization_version u32              = 2
llama_model_loader: - type  f32:   61 tensors
llama_model_loader: - type q5_0:  166 tensors
llama_model_loader: - type q8_0:   15 tensors
llama_model_loader: - type q4_K:   16 tensors
llama_model_loader: - type q6_K:   14 tensors
print_info: file format = GGUF V3 (latest)
print_info: file type   = Q4_K - Medium
print_info: file size   = 98.87 MiB (6.17 BPW) 
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
  
May 10, 2025 > 21:04:34 |  serve._cli.task : 33 |   ❌ ERROR  |  task: [serve] echo "Starting LlamaCpp server and waiting for it to be ready..."
task: [serve] if [ "$(docker ps -q --filter "status=exited" -f name=lmorbits-llamacpp-rag_model)" ]; then
  docker start lmorbits-llamacpp-rag_model
  container_id=$(docker ps -aqf "name=lmorbits-llamacpp-rag_model")
else
  container_id=$(docker run -d \
    --name lmorbits-llamacpp-rag_model \
    -p 8080:8080 \
    -v /Users/parsa/Desk/projects/university/slmops-project/slmops-thesis/app_projects/app/pyapp/notebooks/models/rag_model/model_path/artifacts:/models \
    ghcr.io/ggerganov/llama.cpp:server \
    -m /models/model.gguf)
fi

echo "🕐 Waiting for LlamaCpp server to become healthy..."
while ! docker logs $container_id 2>&1 | grep -q "GET /health 127.0.0.1 200"; do
  echo "⏳ Still starting..."
  docker logs --tail 10 $container_id
  sleep 1
done

echo "✅ LlamaCpp server is ready!"

docker: Error response from daemon: Conflict. The container name "/lmorbits-llamacpp-rag_model" is already in use by container "9ec29e05b8579e38d3548f71cad8d0f26823f8078eb7a9e23b003843be098f5c". You have to remove (or rename) that container to be able to reuse that name.
See 'docker run --help'.
task: Failed to run task "serve": exit status 125
  
May 10, 2025 > 21:06:13 |  serve._cli.task : 33 |   ❌ ERROR  |  task: [serve] echo "Starting LlamaCpp server and waiting for it to be ready..."
task: [serve] if [ "$(docker ps -q --filter "status=exited" -f name=lmorbits-llamacpp-rag_model)" ]; then
  docker start lmorbits-llamacpp-rag_model
  container_id=$(docker ps -aqf "name=lmorbits-llamacpp-rag_model")
else
  container_id=$(docker run -d \
    --name lmorbits-llamacpp-rag_model \
    -p 8080:8080 \
    -v /Users/parsa/Desk/projects/university/slmops-project/slmops-thesis/app_projects/app/pyapp/notebooks/models/rag_model/model_path/artifacts:/models \
    ghcr.io/ggerganov/llama.cpp:server \
    -m /models/model.gguf)
fi

echo "🕐 Waiting for LlamaCpp server to become healthy..."
while ! docker logs $container_id 2>&1 | grep -q "GET /health 127.0.0.1 200"; do
  echo "⏳ Still starting..."
  docker logs --tail 10 $container_id
  sleep 1
done

echo "✅ LlamaCpp server is ready!"

llama_model_loader: - kv  28:            tokenizer.ggml.unknown_token_id u32              = 0
llama_model_loader: - kv  29:               general.quantization_version u32              = 2
llama_model_loader: - type  f32:   61 tensors
llama_model_loader: - type q5_0:  166 tensors
llama_model_loader: - type q8_0:   15 tensors
llama_model_loader: - type q4_K:   16 tensors
llama_model_loader: - type q6_K:   14 tensors
print_info: file format = GGUF V3 (latest)
print_info: file type   = Q4_K - Medium
print_info: file size   = 98.87 MiB (6.17 BPW) 
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
  
May 10, 2025 > 21:07:09 |  taskpy.main : 34 |   ❌ ERROR  |  task: [remove] if [ "$(docker ps -q -f name=lmorbits-obeservation)" ]; then
     docker stop $(docker ps -q -f name=lmorbits-obeservation)
     
   fi
   docker rm $(docker ps -aq -f name=lmorbits-obeservation)

"docker rm" requires at least 1 argument.
See 'docker rm --help'.

Usage:  docker rm [OPTIONS] CONTAINER [CONTAINER...]

Remove one or more containers
task: Failed to run task "remove": exit status 1
  
May 11, 2025 > 14:19:13 |  serve._cli.task : 33 |   ❌ ERROR  |  "docker rm" requires at least 1 argument.
See 'docker rm --help'.

Usage:  docker rm [OPTIONS] CONTAINER [CONTAINER...]

Remove one or more containers
task: Failed to run task "delete": exit status 1
  
May 11, 2025 > 14:20:06 |  serve._cli.task : 33 |   ❌ ERROR  |  "docker rm" requires at least 1 argument.
See 'docker rm --help'.

Usage:  docker rm [OPTIONS] CONTAINER [CONTAINER...]

Remove one or more containers
task: Failed to run task "delete": exit status 1
  
May 11, 2025 > 14:20:38 |  serve._cli.task : 33 |   ❌ ERROR  |  task: [serve] echo "Starting LlamaCpp server and waiting for it to be ready..."
task: [serve] if [ "$(docker ps -q --filter "status=exited" -f name=lmorbits-llamacpp-rag_model)" ]; then
  docker start lmorbits-llamacpp-rag_model
  container_id=$(docker ps -aqf "name=lmorbits-llamacpp-rag_model")
else
  container_id=$(docker run -d \
    --name lmorbits-llamacpp-rag_model \
    -p 8080:8080 \
    -v /Users/parsa/Desk/projects/university/slmops-project/slmops-thesis/app_projects/app/pyapp/notebooks/embed/models/rag_model/model_path/artifacts:/models \
    ghcr.io/ggerganov/llama.cpp:server \
    -m /models/model.gguf)
fi

echo "🕐 Waiting for LlamaCpp server to become healthy..."
while ! docker logs $container_id 2>&1 | grep -q "GET /health 127.0.0.1 200"; do
  echo "⏳ Still starting..."
  docker logs --tail 10 $container_id
  sleep 1
done

echo "✅ LlamaCpp server is ready!"

llama_model_loader: - kv  28:            tokenizer.ggml.unknown_token_id u32              = 0
llama_model_loader: - kv  29:               general.quantization_version u32              = 2
llama_model_loader: - type  f32:   61 tensors
llama_model_loader: - type q5_0:  166 tensors
llama_model_loader: - type q8_0:   15 tensors
llama_model_loader: - type q4_K:   16 tensors
llama_model_loader: - type q6_K:   14 tensors
print_info: file format = GGUF V3 (latest)
print_info: file type   = Q4_K - Medium
print_info: file size   = 98.87 MiB (6.17 BPW) 
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
  
May 11, 2025 > 14:31:32 |  serve._cli.task : 33 |   ❌ ERROR  |  task: [delete] if [ "$(docker ps -q -f name=lmorbits-embedding-rag_models)" ]; then 
  if [ "$(docker ps -q --filter "status=running" -f name=lmorbits-embedding-rag_models)" ]; then
    echo "Stopping lmorbits-embedding-rag_models"
    docker stop lmorbits-embedding-rag_models
  fi
  echo "Removing lmorbits-embedding-rag_models"
  docker rm lmorbits-embedding-rag_models
else
  echo "lmorbits-embedding-rag_models is not running"
fi

  
May 11, 2025 > 14:32:51 |  serve._cli.task : 33 |   ❌ ERROR  |  task: [delete] if [ "$(docker ps -q -f name=lmorbits-embedding-rag_models)" ]; then 
  if [ "$(docker ps -q --filter "status=running" -f name=lmorbits-embedding-rag_models)" ]; then
    echo "Stopping lmorbits-embedding-rag_models"
    docker stop lmorbits-embedding-rag_models
  fi
  echo "Removing lmorbits-embedding-rag_models"
  docker rm lmorbits-embedding-rag_models
else
  echo "lmorbits-embedding-rag_models is not running"
fi

  
May 11, 2025 > 14:33:28 |  serve._cli.task : 33 |   ❌ ERROR  |  task: [delete] if [ "$(docker ps -q -f name=lmorbits-embedding-rag_embeddings)" ]; then 
  if [ "$(docker ps -q --filter "status=running" -f name=lmorbits-embedding-rag_embeddings)" ]; then
    echo "Stopping lmorbits-embedding-rag_embeddings"
    docker stop lmorbits-embedding-rag_embeddings
  fi
  echo "Removing lmorbits-embedding-rag_embeddings"
  docker rm lmorbits-embedding-rag_embeddings
else
  echo "lmorbits-embedding-rag_embeddings is not running"
fi

  
May 11, 2025 > 14:33:50 |  serve._cli.task : 33 |   ❌ ERROR  |  task: [serve] if [ "$(docker ps -q --filter "status=running" -f name=lmorbits-embedding-rag_embeddings)" ]; then
  echo "lmorbits-embedding-rag_embeddings is already running"
elif [ "$(docker ps -q --filter "status=exited" -f name=lmorbits-embedding-rag_embeddings)" ]; then
  echo "Starting lmorbits-embedding-rag_embeddings"
  docker start lmorbits-embedding-rag_embeddings
else
  echo "Building lmorbits-embedding-image image"
  docker build -t lmorbits-embedding-image -f Dockerfile .
  docker run -d -p 1111:1111 --name lmorbits-embedding-rag_embeddings lmorbits-embedding-image
fi
# health check on /health endpoint
until curl -s http://localhost:1111/health | grep -q "ok"; do
  echo "Waiting for lmorbits-embedding-rag_embeddings to be ready..."
  sleep 1
done

#0 building with "orbstack" instance using docker driver

#1 [internal] load build definition from Dockerfile
#1 transferring dockerfile: 317B done
#1 DONE 0.0s

#2 [internal] load metadata for ghcr.io/astral-sh/uv:python3.13-bookworm-slim
#2 DONE 0.7s

#3 [internal] load .dockerignore
#3 transferring context: 102B done
#3 DONE 0.0s

#4 [1/6] FROM ghcr.io/astral-sh/uv:python3.13-bookworm-slim@sha256:d0f50b72ce818caf18da58e8d41cb9f2cb6ef21cd42a12d46efa8e52c17ff87c
#4 DONE 0.0s

#5 [internal] load build context
#5 transferring context: 190.20kB 0.0s done
#5 DONE 0.0s

#6 [2/6] WORKDIR /app
#6 CACHED

#7 [5/6] RUN uv sync
#7 CACHED

#8 [3/6] COPY pyproject.toml .
#8 CACHED

#9 [4/6] COPY uv.lock .
#9 CACHED

#10 [6/6] COPY . .
#10 CACHED

#11 exporting to image
#11 exporting layers done
#11 writing image sha256:13aa3e85d59daa24f510d7aad0d262b9e238456ad5b8a7a164025d21e66edec8 done
#11 naming to docker.io/library/lmorbits-embedding-image done
#11 DONE 0.0s

View build details: docker-desktop://dashboard/build/orbstack/orbstack/u93nzaszobs6iouyytl4p7wtk
  
May 11, 2025 > 14:33:50 |  serve._cli.task : 33 |   ❌ ERROR  |  task: [stop] if [ "$(docker ps -q --filter "status=exited" -f name=lmorbits-embedding-rag_embeddings)" ]; then
  docker stop lmorbits-embedding-rag_embeddings
fi

  
May 11, 2025 > 14:48:21 |  serve._cli.task : 33 |   ❌ ERROR  |  task: [serve] if [ "$(docker ps -q --filter "status=running" -f name=lmorbits-embedding-rag_embeddings)" ]; then
  echo "lmorbits-embedding-rag_embeddings is already running"
elif [ "$(docker ps -q --filter "status=exited" -f name=lmorbits-embedding-rag_embeddings)" ]; then
  echo "Starting lmorbits-embedding-rag_embeddings"
  docker start lmorbits-embedding-rag_embeddings
else
  echo "Building lmorbits-embedding-image image"
  docker build -t lmorbits-embedding-image -f Dockerfile .
  docker run -d -p 1111:1111 --name lmorbits-embedding-rag_embeddings lmorbits-embedding-image
fi
# health check on /health endpoint
until curl -s http://localhost:1111/health | grep -q "ok"; do
  echo "Waiting for lmorbits-embedding-rag_embeddings to be ready..."
  sleep 1
done

  
May 11, 2025 > 14:48:21 |  serve._cli.task : 33 |   ❌ ERROR  |  task: [stop] if [ "$(docker ps -q --filter "status=exited" -f name=lmorbits-embedding-rag_embeddings)" ]; then
  docker stop lmorbits-embedding-rag_embeddings
fi

  
May 11, 2025 > 14:49:23 |  serve._cli.task : 33 |   ❌ ERROR  |  task: [serve] if [ "$(docker ps -q --filter "status=running" -f name=lmorbits-embedding-rag_embeddings)" ]; then
  echo "lmorbits-embedding-rag_embeddings is already running"
elif [ "$(docker ps -q --filter "status=exited" -f name=lmorbits-embedding-rag_embeddings)" ]; then
  echo "Starting lmorbits-embedding-rag_embeddings"
  docker start lmorbits-embedding-rag_embeddings
else
  echo "Building lmorbits-embedding-image image"
  docker build -t lmorbits-embedding-image -f Dockerfile .
  docker run -d -p 1111:1111 --name lmorbits-embedding-rag_embeddings lmorbits-embedding-image
fi
# health check on /health endpoint
until curl -s http://localhost:1111/health | grep -q "ok"; do
  echo "Waiting for lmorbits-embedding-rag_embeddings to be ready..."
  sleep 1
done

  
May 11, 2025 > 14:49:23 |  serve._cli.task : 33 |   ❌ ERROR  |  task: [stop] if [ "$(docker ps -q --filter "status=exited" -f name=lmorbits-embedding-rag_embeddings)" ]; then
  docker stop lmorbits-embedding-rag_embeddings
fi

  
May 11, 2025 > 14:50:24 |  serve._cli.task : 33 |   ❌ ERROR  |  task: [serve] if [ "$(docker ps -q --filter "status=running" -f name=lmorbits-embedding-rag_embeddings)" ]; then
  echo "lmorbits-embedding-rag_embeddings is already running"
elif [ "$(docker ps -q --filter "status=exited" -f name=lmorbits-embedding-rag_embeddings)" ]; then
  echo "Starting lmorbits-embedding-rag_embeddings"
  docker start lmorbits-embedding-rag_embeddings
else
  echo "Building lmorbits-embedding-image image"
  docker build -t lmorbits-embedding-image -f Dockerfile .
  docker run -d -p 1111:1111 --name lmorbits-embedding-rag_embeddings lmorbits-embedding-image
fi
# health check on /health endpoint
until curl -s http://localhost:1111/health | grep -q "ok"; do
  echo "Waiting for lmorbits-embedding-rag_embeddings to be ready..."
  sleep 1
done

  
May 11, 2025 > 14:50:24 |  serve._cli.task : 33 |   ❌ ERROR  |  task: [stop] if [ "$(docker ps -q --filter "status=exited" -f name=lmorbits-embedding-rag_embeddings)" ]; then
  docker stop lmorbits-embedding-rag_embeddings
fi

  
May 11, 2025 > 14:50:44 |  serve._cli.task : 33 |   ❌ ERROR  |  task: [serve] if [ "$(docker ps -q --filter "status=running" -f name=lmorbits-embedding-rag_embeddings)" ]; then
  echo "lmorbits-embedding-rag_embeddings is already running"
elif [ "$(docker ps -q --filter "status=exited" -f name=lmorbits-embedding-rag_embeddings)" ]; then
  echo "Starting lmorbits-embedding-rag_embeddings"
  docker start lmorbits-embedding-rag_embeddings
else
  echo "Building lmorbits-embedding-image image"
  docker build -t lmorbits-embedding-image -f Dockerfile .
  docker run -d -p 1111:1111 --name lmorbits-embedding-rag_embeddings lmorbits-embedding-image
fi
# health check on /health endpoint
until curl -s http://localhost:1111/health | grep -q "ok"; do
  echo "Waiting for lmorbits-embedding-rag_embeddings to be ready..."
  sleep 1
done

  
May 11, 2025 > 14:50:44 |  serve._cli.task : 33 |   ❌ ERROR  |  task: [stop] if [ "$(docker ps -q --filter "status=exited" -f name=lmorbits-embedding-rag_embeddings)" ]; then
  docker stop lmorbits-embedding-rag_embeddings
fi

  
May 11, 2025 > 14:51:34 |  serve._cli.task : 33 |   ❌ ERROR  |  task: [serve] if [ "$(docker ps -q --filter "status=running" -f name=lmorbits-embedding-rag_embeddings)" ]; then
  echo "lmorbits-embedding-rag_embeddings is already running"
elif [ "$(docker ps -q --filter "status=exited" -f name=lmorbits-embedding-rag_embeddings)" ]; then
  echo "Starting lmorbits-embedding-rag_embeddings"
  docker start lmorbits-embedding-rag_embeddings
else
  echo "Building lmorbits-embedding-image image"
  docker build -t lmorbits-embedding-image -f Dockerfile .
  docker run -d -p 1111:1111 --name lmorbits-embedding-rag_embeddings lmorbits-embedding-image
fi
# health check on /health endpoint
until curl -s http://localhost:1111/health | grep -q "ok"; do
  echo "Waiting for lmorbits-embedding-rag_embeddings to be ready..."
  sleep 1
done

  
May 11, 2025 > 14:51:34 |  serve._cli.task : 33 |   ❌ ERROR  |  task: [stop] if [ "$(docker ps -q --filter "status=exited" -f name=lmorbits-embedding-rag_embeddings)" ]; then
  docker stop lmorbits-embedding-rag_embeddings
fi

  
May 11, 2025 > 14:51:37 |  serve._cli.task : 33 |   ❌ ERROR  |  task: [serve] if [ "$(docker ps -q --filter "status=running" -f name=lmorbits-embedding-rag_embeddings)" ]; then
  echo "lmorbits-embedding-rag_embeddings is already running"
elif [ "$(docker ps -q --filter "status=exited" -f name=lmorbits-embedding-rag_embeddings)" ]; then
  echo "Starting lmorbits-embedding-rag_embeddings"
  docker start lmorbits-embedding-rag_embeddings
else
  echo "Building lmorbits-embedding-image image"
  docker build -t lmorbits-embedding-image -f Dockerfile .
  docker run -d -p 1111:1111 --name lmorbits-embedding-rag_embeddings lmorbits-embedding-image
fi
# health check on /health endpoint
until curl -s http://localhost:1111/health | grep -q "ok"; do
  echo "Waiting for lmorbits-embedding-rag_embeddings to be ready..."
  sleep 1
done

  
May 11, 2025 > 14:51:37 |  serve._cli.task : 33 |   ❌ ERROR  |  task: [stop] if [ "$(docker ps -q --filter "status=exited" -f name=lmorbits-embedding-rag_embeddings)" ]; then
  docker stop lmorbits-embedding-rag_embeddings
fi

  
May 11, 2025 > 14:52:25 |  serve._cli.task : 33 |   ❌ ERROR  |  task: [serve] if [ "$(docker ps -q --filter "status=running" -f name=lmorbits-embedding-rag_embeddings)" ]; then
  echo "lmorbits-embedding-rag_embeddings is already running"
elif [ "$(docker ps -q --filter "status=exited" -f name=lmorbits-embedding-rag_embeddings)" ]; then
  echo "Starting lmorbits-embedding-rag_embeddings"
  docker start lmorbits-embedding-rag_embeddings
else
  echo "Building lmorbits-embedding-image image"
  docker build -t lmorbits-embedding-image -f Dockerfile .
  docker run -d -p 1111:1111 --name lmorbits-embedding-rag_embeddings lmorbits-embedding-image
fi
# health check on /health endpoint
until curl -s http://localhost:1111/health | grep -q "ok"; do
  echo "Waiting for lmorbits-embedding-rag_embeddings to be ready..."
  sleep 1
done

  
May 11, 2025 > 14:52:25 |  serve._cli.task : 33 |   ❌ ERROR  |  task: [stop] if [ "$(docker ps -q --filter "status=exited" -f name=lmorbits-embedding-rag_embeddings)" ]; then
  docker stop lmorbits-embedding-rag_embeddings
fi

  
May 11, 2025 > 14:52:46 |  serve._cli.task : 33 |   ❌ ERROR  |  task: [serve] if [ "$(docker ps -q --filter "status=running" -f name=lmorbits-embedding-rag_embeddings)" ]; then
  echo "lmorbits-embedding-rag_embeddings is already running"
elif [ "$(docker ps -q --filter "status=exited" -f name=lmorbits-embedding-rag_embeddings)" ]; then
  echo "Starting lmorbits-embedding-rag_embeddings"
  docker start lmorbits-embedding-rag_embeddings
else
  echo "Building lmorbits-embedding-image image"
  docker build -t lmorbits-embedding-image -f Dockerfile .
  docker run -d -p 1111:1111 --name lmorbits-embedding-rag_embeddings lmorbits-embedding-image
fi
# health check on /health endpoint
until curl -s http://localhost:1111/health | grep -q "ok"; do
  echo "Waiting for lmorbits-embedding-rag_embeddings to be ready..."
  sleep 1
done

  
May 11, 2025 > 14:52:46 |  serve._cli.task : 33 |   ❌ ERROR  |  task: [stop] if [ "$(docker ps -q --filter "status=exited" -f name=lmorbits-embedding-rag_embeddings)" ]; then
  docker stop lmorbits-embedding-rag_embeddings
fi

  
May 11, 2025 > 15:33:12 |  serve._cli.task : 33 |   ❌ ERROR  |  task: [delete] if [ "$(docker ps -q -f name=lmorbits-embedding-rag_embeddings)" ]; then 
  if [ "$(docker ps -q --filter "status=running" -f name=lmorbits-embedding-rag_embeddings)" ]; then
    echo "Stopping lmorbits-embedding-rag_embeddings"
    docker stop lmorbits-embedding-rag_embeddings
  fi
  echo "Removing lmorbits-embedding-rag_embeddings"
  docker rm lmorbits-embedding-rag_embeddings
else
  echo "lmorbits-embedding-rag_embeddings is not running"
fi

  
May 11, 2025 > 15:33:33 |  serve._cli.task : 33 |   ❌ ERROR  |  task: [serve] if [ "$(docker ps -q --filter "status=running" -f name=lmorbits-embedding-rag_embeddings)" ]; then
  echo "lmorbits-embedding-rag_embeddings is already running"
elif [ "$(docker ps -q --filter "status=exited" -f name=lmorbits-embedding-rag_embeddings)" ]; then
  echo "Starting lmorbits-embedding-rag_embeddings"
  docker start lmorbits-embedding-rag_embeddings
else
  echo "Building lmorbits-embedding-image image"
  docker build -t lmorbits-embedding-image -f Dockerfile .
  docker run -d -p 1111:1111 --name lmorbits-embedding-rag_embeddings lmorbits-embedding-image
fi
# health check on /health endpoint
until curl -s http://localhost:1111/health | grep -q "ok"; do
  echo "Waiting for lmorbits-embedding-rag_embeddings to be ready..."
  sleep 1
done

#0 building with "orbstack" instance using docker driver

#1 [internal] load build definition from Dockerfile
#1 transferring dockerfile: 317B done
#1 DONE 0.0s

#2 [internal] load metadata for ghcr.io/astral-sh/uv:python3.13-bookworm-slim
#2 DONE 0.6s

#3 [internal] load .dockerignore
#3 transferring context: 102B done
#3 DONE 0.0s

#4 [1/6] FROM ghcr.io/astral-sh/uv:python3.13-bookworm-slim@sha256:d0f50b72ce818caf18da58e8d41cb9f2cb6ef21cd42a12d46efa8e52c17ff87c
#4 DONE 0.0s

#5 [internal] load build context
#5 transferring context: 190.20kB 0.0s done
#5 DONE 0.0s

#6 [5/6] RUN uv sync
#6 CACHED

#7 [4/6] COPY uv.lock .
#7 CACHED

#8 [2/6] WORKDIR /app
#8 CACHED

#9 [3/6] COPY pyproject.toml .
#9 CACHED

#10 [6/6] COPY . .
#10 CACHED

#11 exporting to image
#11 exporting layers done
#11 writing image sha256:13aa3e85d59daa24f510d7aad0d262b9e238456ad5b8a7a164025d21e66edec8 done
#11 naming to docker.io/library/lmorbits-embedding-image done
#11 DONE 0.0s

View build details: docker-desktop://dashboard/build/orbstack/orbstack/wi8p1c4otvhsko06xx7p06t0j
  
May 11, 2025 > 15:35:21 |  serve._cli.task : 33 |   ❌ ERROR  |  task: [serve] if [ "$(docker ps -q --filter "status=running" -f name=lmorbits-embedding-rag_embeddings)" ]; then
  echo "lmorbits-embedding-rag_embeddings is already running"
elif [ "$(docker ps -q --filter "status=exited" -f name=lmorbits-embedding-rag_embeddings)" ]; then
  echo "Starting lmorbits-embedding-rag_embeddings"
  docker start lmorbits-embedding-rag_embeddings
else
  echo "Building lmorbits-embedding-image image"
  docker build -t lmorbits-embedding-image -f Dockerfile .
  docker run -d -p 1111:1111 --name lmorbits-embedding-rag_embeddings lmorbits-embedding-image
fi
# health check on /health endpoint
until curl -s http://localhost:1111/health | grep -q "ok"; do
  echo "Waiting for lmorbits-embedding-rag_embeddings to be ready..."
  sleep 1
done

  
May 11, 2025 > 15:35:51 |  serve._cli.task : 33 |   ❌ ERROR  |  task: [serve] if [ "$(docker ps -q --filter "status=running" -f name=lmorbits-embedding-rag_embeddings)" ]; then
  echo "lmorbits-embedding-rag_embeddings is already running"
elif [ "$(docker ps -q --filter "status=exited" -f name=lmorbits-embedding-rag_embeddings)" ]; then
  echo "Starting lmorbits-embedding-rag_embeddings"
  docker start lmorbits-embedding-rag_embeddings
else
  echo "Building lmorbits-embedding-image image"
  docker build -t lmorbits-embedding-image -f Dockerfile .
  docker run -d -p 1111:1111 --name lmorbits-embedding-rag_embeddings lmorbits-embedding-image
fi
# health check on /health endpoint
until curl -s http://localhost:1111/health | grep -q "ok"; do
  echo "Waiting for lmorbits-embedding-rag_embeddings to be ready..."
  sleep 1
done

  
May 11, 2025 > 15:41:04 |  serve._cli.task : 33 |   ❌ ERROR  |  task: [serve] if [ "$(docker ps -q --filter "status=running" -f name=lmorbits-embedding-rag_embeddings)" ]; then
  echo "lmorbits-embedding-rag_embeddings is already running"
elif [ "$(docker ps -q --filter "status=exited" -f name=lmorbits-embedding-rag_embeddings)" ]; then
  echo "Starting lmorbits-embedding-rag_embeddings"
  docker start lmorbits-embedding-rag_embeddings
else
  echo "Building lmorbits-embedding-image image"
  docker build -t lmorbits-embedding-image -f Dockerfile .
  docker run -d -p 1111:1111 --name lmorbits-embedding-rag_embeddings lmorbits-embedding-image
fi
# health check on /health endpoint
until curl -s http://localhost:1111/health | grep -q "ok"; do
  echo "Waiting for lmorbits-embedding-rag_embeddings to be ready..."
  sleep 1
done

  
May 11, 2025 > 15:48:19 |  serve._cli.task : 33 |   ❌ ERROR  |  task: [delete] if [ "$(docker ps -q -f name=lmorbits-embedding-rag_embeddings)" ]; then 
  if [ "$(docker ps -q --filter "status=running" -f name=lmorbits-embedding-rag_embeddings)" ]; then
    echo "Stopping lmorbits-embedding-rag_embeddings"
    docker stop lmorbits-embedding-rag_embeddings
  fi
  echo "Removing lmorbits-embedding-rag_embeddings"
  docker rm lmorbits-embedding-rag_embeddings
else
  echo "lmorbits-embedding-rag_embeddings is not running"
fi

  
May 11, 2025 > 15:48:40 |  serve._cli.task : 33 |   ❌ ERROR  |  task: [serve] if [ "$(docker ps -q --filter "status=running" -f name=lmorbits-embedding-rag_embeddings)" ]; then
  echo "lmorbits-embedding-rag_embeddings is already running"
elif [ "$(docker ps -q --filter "status=exited" -f name=lmorbits-embedding-rag_embeddings)" ]; then
  echo "Starting lmorbits-embedding-rag_embeddings"
  docker start lmorbits-embedding-rag_embeddings
else
  echo "Building lmorbits-embedding-image image"
  docker build -t lmorbits-embedding-image -f Dockerfile .
  docker run -d -p 1111:1111 --name lmorbits-embedding-rag_embeddings lmorbits-embedding-image
fi
# health check on /health endpoint
until curl -s http://localhost:1111/health | grep -q "ok"; do
  echo "Waiting for lmorbits-embedding-rag_embeddings to be ready..."
  sleep 1
done

#0 building with "orbstack" instance using docker driver

#1 [internal] load build definition from Dockerfile
#1 transferring dockerfile: 317B done
#1 DONE 0.0s

#2 [internal] load metadata for ghcr.io/astral-sh/uv:python3.13-bookworm-slim
#2 DONE 0.7s

#3 [internal] load .dockerignore
#3 transferring context: 102B done
#3 DONE 0.0s

#4 [1/6] FROM ghcr.io/astral-sh/uv:python3.13-bookworm-slim@sha256:d0f50b72ce818caf18da58e8d41cb9f2cb6ef21cd42a12d46efa8e52c17ff87c
#4 DONE 0.0s

#5 [internal] load build context
#5 transferring context: 190.13kB 0.0s done
#5 DONE 0.0s

#6 [4/6] COPY uv.lock .
#6 CACHED

#7 [2/6] WORKDIR /app
#7 CACHED

#8 [3/6] COPY pyproject.toml .
#8 CACHED

#9 [5/6] RUN uv sync
#9 CACHED

#10 [6/6] COPY . .
#10 CACHED

#11 exporting to image
#11 exporting layers done
#11 writing image sha256:7f41a5fff1e8b2b43a203f5f0a274c22eb53ff3e8713b4d7f1dea8f9def6aaac done
#11 naming to docker.io/library/lmorbits-embedding-image done
#11 DONE 0.0s

View build details: docker-desktop://dashboard/build/orbstack/orbstack/mmzppuurtfidklrfbwebvb5ix
  
May 11, 2025 > 15:50:27 |  serve._cli.task : 33 |   ❌ ERROR  |  "docker rm" requires at least 1 argument.
See 'docker rm --help'.

Usage:  docker rm [OPTIONS] CONTAINER [CONTAINER...]

Remove one or more containers
task: Failed to run task "delete": exit status 1
  
May 11, 2025 > 15:50:59 |  serve._cli.task : 33 |   ❌ ERROR  |  task: [serve] echo "Starting LlamaCpp server and waiting for it to be ready..."
task: [serve] if [ "$(docker ps -q --filter "status=exited" -f name=lmorbits-llamacpp-rag_model)" ]; then
  docker start lmorbits-llamacpp-rag_model
  container_id=$(docker ps -aqf "name=lmorbits-llamacpp-rag_model")
else
  container_id=$(docker run -d \
    --name lmorbits-llamacpp-rag_model \
    -p 8080:8080 \
    -v /Users/parsa/Desk/projects/university/slmops-project/slmops-thesis/app_projects/app/pyapp/notebooks/embed/models/rag_model/model_path/artifacts:/models \
    ghcr.io/ggerganov/llama.cpp:server \
    -m /models/model.gguf)
fi

echo "🕐 Waiting for LlamaCpp server to become healthy..."
while ! docker logs $container_id 2>&1 | grep -q "GET /health 127.0.0.1 200"; do
  echo "⏳ Still starting..."
  docker logs --tail 10 $container_id
  sleep 1
done

echo "✅ LlamaCpp server is ready!"

llama_model_loader: - kv  28:            tokenizer.ggml.unknown_token_id u32              = 0
llama_model_loader: - kv  29:               general.quantization_version u32              = 2
llama_model_loader: - type  f32:   61 tensors
llama_model_loader: - type q5_0:  166 tensors
llama_model_loader: - type q8_0:   15 tensors
llama_model_loader: - type q4_K:   16 tensors
llama_model_loader: - type q6_K:   14 tensors
print_info: file format = GGUF V3 (latest)
print_info: file type   = Q4_K - Medium
print_info: file size   = 98.87 MiB (6.17 BPW) 
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
  
May 11, 2025 > 16:03:15 |  serve._cli.task : 33 |   ❌ ERROR  |  task: [serve] echo "Starting LlamaCpp server and waiting for it to be ready..."
task: [serve] if [ "$(docker ps -q --filter "status=exited" -f name=lmorbits-llamacpp-rag_model)" ]; then
  docker start lmorbits-llamacpp-rag_model
  container_id=$(docker ps -aqf "name=lmorbits-llamacpp-rag_model")
else
  container_id=$(docker run -d \
    --name lmorbits-llamacpp-rag_model \
    -p 8080:8080 \
    -v /Users/parsa/Desk/projects/university/slmops-project/slmops-thesis/app_projects/app/pyapp/notebooks/embed/models/rag_model/model_path/artifacts:/models \
    ghcr.io/ggerganov/llama.cpp:server \
    -m /models/model.gguf)
fi

echo "🕐 Waiting for LlamaCpp server to become healthy..."
while ! docker logs $container_id 2>&1 | grep -q "GET /health 127.0.0.1 200"; do
  echo "⏳ Still starting..."
  docker logs --tail 10 $container_id
  sleep 1
done

echo "✅ LlamaCpp server is ready!"

llama_model_loader: - kv  28:            tokenizer.ggml.unknown_token_id u32              = 0
llama_model_loader: - kv  29:               general.quantization_version u32              = 2
llama_model_loader: - type  f32:   61 tensors
llama_model_loader: - type q5_0:  166 tensors
llama_model_loader: - type q8_0:   15 tensors
llama_model_loader: - type q4_K:   16 tensors
llama_model_loader: - type q6_K:   14 tensors
print_info: file format = GGUF V3 (latest)
print_info: file type   = Q4_K - Medium
print_info: file size   = 98.87 MiB (6.17 BPW) 
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
<|im_start|>user
Hello<|im_end|>
<|im_start|>assistant
Hi there<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
'
main: server is listening on http://0.0.0.0:8080 - starting the main loop
srv  update_slots: all slots are idle
  
